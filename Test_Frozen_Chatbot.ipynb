{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_v2 import build_lm_classifier_tagger_inference, LSTM_SAVED_STATE\n",
    "from utils import get_batch_classifier_inference, clean_text_v4 as clean_text\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we import the graph_def into a new Graph and returns it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph(\"109_Bank/checkpoints/chatbot_frozen/frozen.pb-723\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = graph.get_tensor_by_name('prefix/LanguageModel/fw_inputs:0')\n",
    "seq_lens = graph.get_tensor_by_name('prefix/LanguageModel/seq_lens:0')\n",
    "char_lens = graph.get_tensor_by_name('prefix/LanguageModel/fw_char_lens:0')\n",
    "bptt = graph.get_tensor_by_name('prefix/LanguageModel/bptt:0')\n",
    "predict_prob = graph.get_tensor_by_name('prefix/Classifier/Softmax:0')\n",
    "predict_tags = graph.get_tensor_by_name('prefix/SequenceTagger/cond/Merge:0')\n",
    "tag_score = graph.get_tensor_by_name('prefix/SequenceTagger/cond/Merge_1:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config, graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('109_Bank/word2idx.json', 'r') as inp:\n",
    "    word2idx = json.load(inp)\n",
    "with open('109_Bank/char2idx.json', 'r') as inp:\n",
    "    char2idx = json.load(inp)\n",
    "word2char = {w: [char2idx[c] for c in w] for w in word2idx}\n",
    "with open('Bank/class2idx.json', 'r') as inp:\n",
    "    class2idx = json.load(inp)\n",
    "    idx2class = {i: w for w, i in class2idx.items()}\n",
    "with open('Bank/tag2idx.json', 'r') as inp:\n",
    "    tag2idx = json.load(inp)\n",
    "    idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(texts, bsz=32):\n",
    "    texts = [clean_text(x.strip()) for x in texts]\n",
    "    texts = np.array([[word2char.get(w, word2char['<UNK>']) for w in sent] for sent in texts])\n",
    "    results = []\n",
    "    for chars, lens, cl in get_batch_classifier_inference(texts, bsz):\n",
    "        res = session.run([predict_prob, predict_tags], feed_dict={\n",
    "            inputs: chars, seq_lens: lens,\n",
    "            char_lens: cl, bptt: 20\n",
    "        })\n",
    "        results.append(res)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[2.6383190e-10, 4.1221051e-07, 2.5529372e-09, 4.4460098e-06,\n",
       "          1.3986401e-10, 4.0912629e-09, 9.9999332e-01, 1.7166562e-06,\n",
       "          1.2660516e-07, 1.8831863e-09, 1.0862812e-09, 4.7357931e-09,\n",
       "          2.1025111e-08, 3.9238179e-10, 3.7833234e-09, 3.3429002e-09,\n",
       "          1.2676178e-08, 1.2719380e-09, 4.1492676e-09]], dtype=float32),\n",
       "  array([[0, 0, 0, 2, 2, 0, 0, 0, 0]], dtype=int32)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(['Dịch vụ 4d secure là gì vậy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
