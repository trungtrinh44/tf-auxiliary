{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from elmo import elmo_embedding\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from model_v2 import LanguageModel\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pos2idx.json', 'r') as inp:\n",
    "    pos2idx = json.load(inp)\n",
    "idx2pos = {v: k for k, v in pos2idx.items()}\n",
    "with open('baomoi_punc/word2idx.json', 'r') as inp:\n",
    "    word2idx = json.load(inp)\n",
    "with open('baomoi_punc/char2idx.json', 'r') as inp:\n",
    "    char2idx = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagger(inputs, labels, seq_lens, n_units, n_classes, drop_i, drop_o, name='tagger', reuse=False, is_training=True):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        def __cell():\n",
    "            cell = tf.contrib.rnn.GRUBlockCellV2(n_units, name='cell', reuse=reuse)\n",
    "            if is_training:\n",
    "                cell = tf.nn.rnn_cell.DropoutWrapper(cell=cell, input_keep_prob=1.0-drop_i, output_keep_prob=1.0-drop_o, variational_recurrent=True, input_size=inputs.shape[-1], dtype=tf.float32)\n",
    "            return cell\n",
    "        outputs, state = tf.nn.bidirectional_dynamic_rnn(__cell(), __cell(), inputs, seq_lens, time_major=False, dtype=tf.float32)\n",
    "        outputs = tf.concat(outputs, axis=-1)\n",
    "        s = tf.shape(outputs)\n",
    "        W = tf.get_variable(name='W', shape=(2 * n_units, n_classes), initializer=tf.glorot_uniform_initializer(), trainable=True)\n",
    "        b = tf.get_variable(name='b', shape=(n_classes, ), initializer=tf.zeros_initializer(), trainable=True)\n",
    "        outputs = tf.reshape(outputs, (s[0] * s[1], s[2]), name='before_proj')\n",
    "        outputs = tf.nn.xw_plus_b(outputs, W, b)\n",
    "        outputs = tf.reshape(outputs, (s[0], s[1], n_classes), name='after_proj')\n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\n",
    "            inputs=outputs,\n",
    "            tag_indices=labels,\n",
    "            sequence_lengths=seq_lens\n",
    "        )\n",
    "        loss = tf.reduce_mean(-log_likelihood)\n",
    "        decode_tags, best_scores = tf.contrib.crf.crf_decode(\n",
    "            potentials=outputs,\n",
    "            transition_params=transition_params,\n",
    "            sequence_length=seq_lens\n",
    "        )\n",
    "        mask = tf.sequence_mask(seq_lens, dtype=tf.float32)\n",
    "        acc = tf.reduce_sum(tf.to_float(tf.equal(decode_tags, labels)) * mask) / tf.reduce_sum(mask)\n",
    "    return outputs, loss, transition_params, decode_tags, best_scores, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "elmo_embedding() missing 1 required positional argument: 'seq_lens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-43b6a1a3e1de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdrop_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drop_i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdrop_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drop_o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0melmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melmo_l2_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melmo_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtag_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: elmo_embedding() missing 1 required positional argument: 'seq_lens'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "session = tf.Session()\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, None, 1024, 4), name='x')\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None, None), name='y')\n",
    "seq_len = tf.placeholder(dtype=tf.int32, shape=(None,), name='seq_len')\n",
    "drop_i = tf.placeholder(dtype=tf.float32, shape=(), name='drop_i')\n",
    "drop_o = tf.placeholder(dtype=tf.float32, shape=(), name='drop_o')\n",
    "elmo, elmo_l2_reg = elmo_embedding(x)\n",
    "outputs, loss, transition_params, decode_tags, best_scores, acc = tagger(elmo, y, seq_len, 200, len(pos2idx), drop_i, drop_o)\n",
    "tag_saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    x = str(unicodedata.normalize('NFKC', x.lower()))\n",
    "    return re.sub('\\d+','N', re.sub('[ ]+',' ', re.sub('[\\n\\r][ \\n\\r]*',' L ', re.sub(r'(?P<punc>\\W)',' \\g<punc> ', x))))\n",
    "\n",
    "def pad_sequence(words):\n",
    "    maxlen = max(len(x) for x in words)\n",
    "    arr = np.zeros(shape=(len(words), 1, maxlen))\n",
    "    for ir in range(len(arr)):\n",
    "        s = words[ir]\n",
    "        arr[ir][0][:len(s)] = s\n",
    "    return arr\n",
    "\n",
    "def __embed_sequence(sentence):\n",
    "    unk_char_idx = char2idx['U']\n",
    "    sentence = [[char2idx.get(x, unk_char_idx) for x in word] for word in sentence]\n",
    "    seq_len = len(sentence)\n",
    "    inputs = pad_sequence(sentence)\n",
    "    embeddings = session.run(lm_model.concated_timewise_output, feed_dict={\n",
    "        lm_model.inputs: inputs, lm_model.seq_lens: [seq_len], lm_model.reset_state: True\n",
    "    })\n",
    "    return embeddings\n",
    "def embed_sentence(sentence):\n",
    "#     sentence = clean_text(sentence).split()\n",
    "    return __embed_sequence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('15/checkpoints/model_configs.json', 'r') as inp:\n",
    "    params = json.load(inp)\n",
    "\n",
    "lm_model = LanguageModel(**params, is_training=False, is_encoding=True)\n",
    "\n",
    "lm_model.build_model()\n",
    "lm_saver = tf.train.Saver([x for x in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'LanguageModel') if x not in tf.get_collection('LSTM_SAVED_STATE')])\n",
    "session.run(tf.global_variables_initializer())\n",
    "lm_saver.restore(session, '15/checkpoints/test/model.cpkt-315616')\n",
    "tag_saver.restore(session, './pos_tagger.cpkt-6600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(sentence):\n",
    "    sentence = clean_text(sentence).split()\n",
    "    em = np.transpose(embed_sentence(sentence), (1, 0, 2, 3))\n",
    "    tags = session.run(decode_tags, feed_dict={\n",
    "        x: em, seq_len: [len(em[0])], drop_i: 0.0, drop_o: 0.0\n",
    "    })\n",
    "    return [(w, idx2pos[t]) for w, t in zip(sentence, tags[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag(\"\"\"Thứ Bảy ngày 08/09 làm seminar lúc 9h30 nhé. Thái Thanh trình bày về cái chatbot của em. Vẫn chưa thấy em post cái gì mà em nói hôm thứ Bảy lên đây cho tôi xem.\n",
    "\n",
    "Duc Trung book phòng nhé.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
