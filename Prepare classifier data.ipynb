{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model_v2 import LanguageModel\n",
    "from tqdm import tqdm_notebook\n",
    "from utils import clean_text\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('102/word2idx.json', 'r') as inp:\n",
    "    word2idx = json.load(inp)\n",
    "with open('102/char2idx.json', 'r') as inp:\n",
    "    char2idx = json.load(inp)\n",
    "idx2word = {k: v for v, k in word2idx.items()}\n",
    "idx2char = {k: v for v, k in char2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion = pd.read_csv('fashion.csv')\n",
    "# music = pd.read_csv('music.csv')\n",
    "# travel = pd.read_csv('travel.csv')\n",
    "# technology = pd.read_csv('technology.csv')\n",
    "# lifestyle = pd.read_csv('lifestyle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion['class'] = 'fashion'\n",
    "# music['class'] = 'music'\n",
    "# travel['class'] = 'travel'\n",
    "# technology['class'] = 'technology'\n",
    "# lifestyle['class'] = 'lifestyle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([fashion, music, travel, technology, lifestyle], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from 102/checkpoints/test/model.cpkt-209107\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "with open('102/checkpoints/model_configs.json', 'r') as inp:\n",
    "    params = json.load(inp)\n",
    "\n",
    "model = LanguageModel(**params, is_training=False, is_encoding=True)\n",
    "\n",
    "model.build_model()\n",
    "saver = tf.train.Saver([x for x in tf.global_variables() if x not in tf.get_collection('LSTM_SAVED_STATE')])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, '102/checkpoints/test/model.cpkt-209107')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = tf.concat([model.encode_outputs[-1], model.layerwise_avg[-1], model.layerwise_max[-1]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(words):\n",
    "    maxlen = max(len(x) for x in words)\n",
    "    arr = np.zeros(shape=(len(words), 1, maxlen))\n",
    "    for ir in range(len(arr)):\n",
    "        s = words[ir]\n",
    "        arr[ir][0][:len(s)] = s\n",
    "    return arr\n",
    "\n",
    "def __embed_sequence(sentence):\n",
    "    unk_char = [char2idx[x] for x in '<UNK>']\n",
    "    sentence = [[char2idx[x] for x in word] if word in word2idx else unk_char for word in sentence]\n",
    "    seq_len = len(sentence)\n",
    "    inputs = pad_sequence(sentence)\n",
    "    embeddings = sess.run(sent_emb, feed_dict={\n",
    "        model.inputs: inputs, model.seq_lens: [seq_len], model.reset_state: True\n",
    "    })\n",
    "    return embeddings\n",
    "def embed_sentence(sentence):\n",
    "    sentence = re.sub(r'(http[s]?://)?(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', sentence)\n",
    "    sentence = re.sub(r\"#[^\\s]*\", ' ', sentence)\n",
    "    sentence = clean_text(sentence, add_bos=True, add_eos=True).split()\n",
    "    return __embed_sequence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('intent.csv')[['label', 'text']]\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3084\n",
       "0    2997\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['price'] = data['label'].map(lambda x: 1 if 'P' in x else 0)\n",
    "data['price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5070\n",
       "1    1011\n",
       "Name: where, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['where'] = data['label'].map(lambda x: 1 if 'W' in x else 0)\n",
    "data['where'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6073\n",
       "1       8\n",
       "Name: time, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['time'] = data['label'].map(lambda x: 1 if 'T' in x else 0)\n",
    "data['time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4831\n",
       "1    1250\n",
       "Name: availability, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['availability'] = data['label'].map(lambda x: 1 if 'A' in x else 0)\n",
    "data['availability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5355\n",
       "1     726\n",
       "Name: interest, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['interest'] = data['label'].map(lambda x: 1 if 'I' in x else 0)\n",
    "data['interest'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4975\n",
       "1    1106\n",
       "Name: other, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['other'] = data['label'].map(lambda x: 1 if 'O' in x else 0)\n",
    "data['other'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vector'] = data[['price','where','time','availability','interest','other']].apply(lambda row: np.array(row, dtype=np.int32), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b7c1df95a44acab0806b9c2039bde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6081), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding = [np.squeeze(embed_sentence(x), 0) for x in tqdm_notebook(data['text'])]    \n",
    "data['embedding'] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split([x for x in zip(data['embedding'], data['text'])], data['vector'], test_size=0.5, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classify data/X_train.pkl', 'wb') as out:\n",
    "    pickle.dump(X_train, out)\n",
    "with open('classify data/y_train.pkl', 'wb') as out:\n",
    "    pickle.dump(y_train, out)\n",
    "with open('classify data/X_test.pkl', 'wb') as out:\n",
    "    pickle.dump(X_test, out)\n",
    "with open('classify data/y_test.pkl', 'wb') as out:\n",
    "    pickle.dump(y_test, out)\n",
    "with open('classify data/X_val.pkl', 'wb') as out:\n",
    "    pickle.dump(X_val, out)\n",
    "with open('classify data/y_val.pkl', 'wb') as out:\n",
    "    pickle.dump(y_val, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
