{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "import unicodedata\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from model_v2 import LanguageModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baomoi_punc/word2idx.json', 'r') as inp:\n",
    "    word2idx = json.load(inp)\n",
    "with open('baomoi_punc/char2idx.json', 'r') as inp:\n",
    "    char2idx = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from 15/checkpoints/test/model.cpkt-315616\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "with open('15/checkpoints/model_configs.json', 'r') as inp:\n",
    "    params = json.load(inp)\n",
    "\n",
    "model = LanguageModel(**params, is_training=False, is_encoding=True)\n",
    "\n",
    "model.build_model()\n",
    "saver = tf.train.Saver([x for x in tf.global_variables() if x not in tf.get_collection('LSTM_SAVED_STATE')])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, '15/checkpoints/test/model.cpkt-315616')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    x = str(unicodedata.normalize('NFKC', x.lower()))\n",
    "    return re.sub('\\d+','N', re.sub('[ ]+',' ', re.sub('[\\n\\r][ \\n\\r]*',' L ', re.sub(r'(?P<punc>\\W)',' \\g<punc> ', x))))\n",
    "\n",
    "def pad_sequence(words):\n",
    "    maxlen = max(len(x) for x in words)\n",
    "    arr = np.zeros(shape=(len(words), 1, maxlen))\n",
    "    for ir in range(len(arr)):\n",
    "        s = words[ir]\n",
    "        arr[ir][0][:len(s)] = s\n",
    "    return arr\n",
    "\n",
    "def __embed_sequence(sentence):\n",
    "    unk_char_idx = char2idx['U']\n",
    "    sentence = [[char2idx.get(x, unk_char_idx) for x in word] for word in sentence]\n",
    "    seq_len = len(sentence)\n",
    "    inputs = pad_sequence(sentence)\n",
    "    embeddings = sess.run(model.concated_timewise_output, feed_dict={\n",
    "        model.inputs: inputs, model.seq_lens: [seq_len], model.reset_state: True\n",
    "    })\n",
    "    return embeddings\n",
    "def embed_sentence(sentence):\n",
    "#     sentence = clean_text(sentence).split()\n",
    "    return __embed_sequence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [os.path.join(p, x) for p, dn, fn in os.walk('VLSP/train') for x in fn if x.endswith('.txt')]\n",
    "test = [os.path.join(p, x) for p, dn, fn in os.walk('VLSP/test') for x in fn if x.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2idx = {}\n",
    "ner2idx = {}\n",
    "def build_data(filenames):\n",
    "    words = []\n",
    "    curr_words = []\n",
    "    pos_tags = []\n",
    "    curr_pos = []\n",
    "    ner_tags = []\n",
    "    curr_ner = []\n",
    "    flag = False\n",
    "    for fn in filenames:\n",
    "        with open(fn, 'r') as inp:\n",
    "            for line in itertools.islice(inp.readlines(), 3, None):\n",
    "                line = line.strip().split('\\t')\n",
    "                if len(line) != 5:\n",
    "                    if flag:\n",
    "                        flag = not flag\n",
    "                        if len(curr_words) > 0 and len(curr_pos) > 0 and len(curr_ner) > 0:\n",
    "                            words.append(curr_words)\n",
    "                            pos_tags.append(curr_pos)\n",
    "                            ner_tags.append(curr_ner)\n",
    "                        else:\n",
    "                            print(fn)\n",
    "                        curr_words = []\n",
    "                        curr_pos = []\n",
    "                        curr_ner = []\n",
    "                    else:\n",
    "                        flag = not flag\n",
    "                    continue\n",
    "                word, _, pos, ner, _ = line\n",
    "                word = word.split('_')\n",
    "                word = [y for x in word for y in clean_text(x).split()]\n",
    "                pos = pos.strip()\n",
    "                pos = [pos if i == 0 or pos == 'O' else 'I-{}'.format(pos[2:]) for i in range(len(word))]\n",
    "                ner = [ner if i == 0 or ner == 'O' else 'I-{}'.format(ner[2:]) for i in range(len(word))]\n",
    "                for p in pos:\n",
    "                    if p not in pos2idx:\n",
    "                        pos2idx[p] = len(pos2idx)\n",
    "                    if p != 'O':\n",
    "                        p = 'I-{}'.format(p[2:])\n",
    "                        if p not in pos2idx:\n",
    "                            pos2idx[p] = len(pos2idx)\n",
    "                for n in ner:\n",
    "                    if n not in ner2idx:\n",
    "                        ner2idx[n] = len(ner2idx)\n",
    "                    if n != 'O':\n",
    "                        n = 'I-{}'.format(n[2:])\n",
    "                        if n not in ner2idx:\n",
    "                            ner2idx[n] = len(ner2idx)\n",
    "                curr_words.extend(word)\n",
    "                curr_pos.extend(pos)\n",
    "                curr_ner.extend(ner)\n",
    "    return words, pos_tags, ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLSP/train/81724.txt\n",
      "VLSP/train/90159.txt\n",
      "VLSP/train/8010.txt\n",
      "VLSP/train/81914.txt\n",
      "VLSP/train/81914.txt\n",
      "VLSP/train/26554.txt\n",
      "VLSP/train/8160.txt\n",
      "VLSP/train/90069.txt\n",
      "VLSP/train/83391.txt\n",
      "VLSP/train/88105.txt\n",
      "VLSP/train/83595.txt\n",
      "VLSP/train/46165.txt\n",
      "VLSP/train/50501.txt\n",
      "VLSP/train/8456.txt\n",
      "VLSP/train/87642.txt\n",
      "VLSP/train/90324.txt\n",
      "VLSP/train/103977.txt\n",
      "VLSP/train/46803.txt\n",
      "VLSP/train/45817.txt\n",
      "VLSP/train/5932.txt\n",
      "VLSP/train/104056.txt\n",
      "VLSP/train/92260.txt\n",
      "VLSP/train/89724.txt\n",
      "VLSP/train/103780.txt\n",
      "VLSP/train/81911.txt\n",
      "VLSP/train/89705.txt\n",
      "VLSP/train/83014.txt\n",
      "VLSP/train/83121.txt\n",
      "VLSP/train/45098.txt\n",
      "VLSP/train/89917.txt\n",
      "VLSP/train/59256.txt\n",
      "VLSP/train/89319.txt\n",
      "VLSP/train/90832.txt\n",
      "VLSP/train/88517.txt\n",
      "VLSP/train/46245.txt\n",
      "VLSP/train/81533.txt\n",
      "VLSP/train/6825.txt\n",
      "VLSP/train/88713.txt\n",
      "VLSP/train/80237.txt\n",
      "VLSP/train/46273.txt\n",
      "VLSP/train/89518.txt\n",
      "VLSP/train/59401.txt\n",
      "VLSP/train/82846.txt\n",
      "VLSP/train/59602.txt\n",
      "VLSP/train/60050.txt\n",
      "VLSP/train/82853.txt\n",
      "VLSP/train/89503.txt\n",
      "VLSP/train/82531.txt\n",
      "VLSP/train/100824.txt\n",
      "VLSP/train/80432.txt\n",
      "VLSP/train/25302.txt\n",
      "VLSP/train/87434.txt\n",
      "VLSP/train/80776.txt\n",
      "VLSP/train/46851.txt\n",
      "VLSP/train/45658.txt\n",
      "VLSP/train/7398.txt\n",
      "VLSP/train/45428.txt\n",
      "VLSP/train/51392.txt\n",
      "VLSP/train/87894.txt\n",
      "VLSP/train/103360.txt\n",
      "VLSP/train/87888.txt\n",
      "VLSP/train/102984.txt\n",
      "VLSP/train/4784.txt\n",
      "VLSP/train/86628.txt\n",
      "VLSP/train/26749.txt\n",
      "VLSP/train/82497.txt\n",
      "VLSP/train/7818.txt\n",
      "VLSP/train/89431.txt\n",
      "VLSP/train/25600.txt\n",
      "VLSP/train/87228.txt\n",
      "VLSP/train/45903.txt\n",
      "VLSP/train/49.txt\n",
      "VLSP/train/46027.txt\n",
      "VLSP/train/80993.txt\n",
      "VLSP/train/103567.txt\n",
      "VLSP/train/46762.txt\n",
      "VLSP/train/85121.txt\n",
      "VLSP/train/51012.txt\n",
      "VLSP/train/25435.txt\n",
      "VLSP/train/45096.txt\n",
      "VLSP/train/45732.txt\n",
      "VLSP/train/51004.txt\n",
      "VLSP/train/51004.txt\n",
      "VLSP/train/51004.txt\n",
      "VLSP/train/51004.txt\n",
      "VLSP/train/51004.txt\n",
      "VLSP/train/51004.txt\n",
      "VLSP/train/103178.txt\n",
      "VLSP/train/89297.txt\n",
      "VLSP/train/90694.txt\n",
      "VLSP/train/25288.txt\n",
      "VLSP/train/58561.txt\n",
      "VLSP/train/104522.txt\n",
      "VLSP/train/25463.txt\n",
      "VLSP/train/25849.txt\n",
      "VLSP/train/51010.txt\n",
      "VLSP/train/9129.txt\n",
      "VLSP/train/7105.txt\n",
      "VLSP/train/89128.txt\n",
      "VLSP/train/104123.txt\n",
      "VLSP/train/82039.txt\n",
      "VLSP/train/46710.txt\n",
      "VLSP/train/25464.txt\n",
      "VLSP/train/59910.txt\n",
      "VLSP/train/50362.txt\n",
      "VLSP/train/82526.txt\n",
      "VLSP/train/25283.txt\n",
      "VLSP/train/50232.txt\n",
      "VLSP/train/82711.txt\n",
      "VLSP/train/59770.txt\n",
      "VLSP/train/25480.txt\n",
      "VLSP/train/59169.txt\n",
      "VLSP/train/87784.txt\n",
      "VLSP/train/46019.txt\n",
      "VLSP/train/86627.txt\n",
      "VLSP/train/4899.txt\n",
      "VLSP/train/46549.txt\n",
      "VLSP/train/25627.txt\n",
      "VLSP/train/25627.txt\n",
      "VLSP/train/51007.txt\n",
      "VLSP/train/51007.txt\n",
      "VLSP/train/6207.txt\n",
      "VLSP/train/90854.txt\n",
      "VLSP/train/86797.txt\n",
      "VLSP/train/88529.txt\n",
      "VLSP/train/45329.txt\n",
      "VLSP/train/81173.txt\n",
      "VLSP/train/88681.txt\n",
      "VLSP/train/89519.txt\n",
      "VLSP/train/6972.txt\n",
      "VLSP/train/86375.txt\n",
      "VLSP/train/80192.txt\n",
      "VLSP/train/45436.txt\n",
      "VLSP/train/60681.txt\n",
      "VLSP/train/82342.txt\n",
      "VLSP/train/60296.txt\n",
      "VLSP/test/106909.txt\n",
      "VLSP/test/109898.txt\n",
      "VLSP/test/108784.txt\n",
      "VLSP/test/109471.txt\n",
      "VLSP/test/107955.txt\n",
      "VLSP/test/105426.txt\n",
      "VLSP/test/106719.txt\n",
      "VLSP/test/107412.txt\n",
      "VLSP/test/106490.txt\n",
      "VLSP/test/108599.txt\n",
      "VLSP/test/107836.txt\n"
     ]
    }
   ],
   "source": [
    "train_data = build_data(train)\n",
    "test_data = build_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16859/16859 [05:09<00:00, 54.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embed = [\n",
    "    np.squeeze(embed_sentence(x), 1) for x in tqdm(train_data[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2830/2830 [00:55<00:00, 50.93it/s]\n"
     ]
    }
   ],
   "source": [
    "test_embed = [\n",
    "    np.squeeze(embed_sentence(x), 1) for x in tqdm(test_data[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16859it [01:23, 202.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, (e, p, n) in enumerate(tqdm(zip(train_embed, train_data[1], train_data[2]))):\n",
    "    np.save('VLSP/train/{}e.npy'.format(i), e)\n",
    "    np.save('VLSP/train/{}p.npy'.format(i), np.array(p))\n",
    "    np.save('VLSP/train/{}n.npy'.format(i), np.array(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2830it [00:15, 184.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, (e, p, n) in enumerate(tqdm(zip(test_embed, test_data[1], test_data[2]))):\n",
    "    np.save('VLSP/test/{}e.npy'.format(i), e)\n",
    "    np.save('VLSP/test/{}p.npy'.format(i), np.array(p))\n",
    "    np.save('VLSP/test/{}n.npy'.format(i), np.array(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pos2idx.json', 'w') as out:\n",
    "    json.dump(pos2idx, out)\n",
    "with open('ner2idx.json', 'w') as out:\n",
    "    json.dump(ner2idx, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-VP': 1,\n",
       " 'I-VP': 2,\n",
       " 'B-NP': 3,\n",
       " 'I-NP': 4,\n",
       " 'B-PP': 5,\n",
       " 'I-PP': 6,\n",
       " 'B-AP': 7,\n",
       " 'I-AP': 8,\n",
       " 'B-IP': 9,\n",
       " 'I-IP': 10,\n",
       " 'B-NPb': 11,\n",
       " 'I-NPb': 12,\n",
       " 'B-VPb': 13,\n",
       " 'I-VPb': 14,\n",
       " 'B-EP': 15,\n",
       " 'I-EP': 16,\n",
       " 'B-MP': 17,\n",
       " 'I-MP': 18,\n",
       " 'I-RP': 19,\n",
       " 'B-PER': 20,\n",
       " 'I-PER': 21}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-LOC': 1,\n",
       " 'I-LOC': 2,\n",
       " 'B-PER': 3,\n",
       " 'I-PER': 4,\n",
       " 'B-ORG': 5,\n",
       " 'I-ORG': 6,\n",
       " 'B-MISC': 7,\n",
       " 'I-MISC': 8}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner2idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
