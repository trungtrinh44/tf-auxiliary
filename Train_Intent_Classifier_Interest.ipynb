{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainer\n",
    "from utils import get_batch_classifier, slanted_triangular_learning_rate\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '107_intent'\n",
    "with open(VERSION+'/word2idx.json', 'r') as inp:\n",
    "    word2idx = json.load(inp)\n",
    "with open(VERSION+'/char2idx.json', 'r') as inp:\n",
    "    char2idx = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer params {'model_configs': {'drop_e': 0.1, 'skip_connection': True, 'projection_dims': 512, 'char_cnn_options': {'n_highways': 2, 'layers': [[1, 16], [2, 16], [3, 32], [4, 64], [5, 128], [6, 256], [7, 512]]}, 'char_vocab_size': 1088, 'vocab_size': 125409, 'rnn_layers': [{'drop_o': 0.2, 'drop_i': 0.2, 'units': 1024, 'wdrop': 0.4}, {'drop_o': 0.2, 'units': 1024, 'wdrop': 0.4}, {'drop_o': 0.2, 'units': 1024, 'wdrop': 0.4}], 'char_vec_size': 16}, 'bptt': 100, 'optimizer': {'params': {'weight_decay': 1.2e-06, 'beta2': 0.99, 'beta1': 0.8}, 'name': 'adamw'}, 'train_summary_dir': '107_intent/train_summary/', 'negative_samples': 10000, 'wdecay': 0.0, 'checkpoint_dir': '107_intent/checkpoints/', 'log_path': '107_intent/logs', 'beta': 1e-06, 'use_ema': True, 'test_summary_dir': '107_intent/test_summary/', 'clip_norm': 0.3, 'save_freq': 1000, 'alpha': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "with open(VERSION+'/trainer_params.json', 'r') as inp:\n",
    "    params = json.load(inp)\n",
    "    \n",
    "my_trainer = trainer.Trainer(**params, fine_tune=True)\n",
    "\n",
    "my_trainer.logger.info('Trainer params {}'.format(params))\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_configs = {\n",
    "    'layers': [\n",
    "        {'batch_norm': False, 'drop_out': 0.2},\n",
    "        {'units': 50, 'batch_norm': False, 'drop_out': 0.1, 'activation': 'relu'}\n",
    "    ], 'n_classes': 2\n",
    "}\n",
    "my_trainer.build_classifier(classifier_configs, folder_name='interest_train', save_optimizer_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from 107_intent/checkpoints/fine_tune_test/model-full.cpkt-81219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from 107_intent/checkpoints/fine_tune_test/model-full.cpkt-81219\n"
     ]
    }
   ],
   "source": [
    "my_trainer.restore_language_model('107_intent/checkpoints/fine_tune_test/model-full.cpkt-81219')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_chars = np.load('IntentDetection/full/class_chars.npy')\n",
    "class_labels = pd.read_csv('IntentDetection/full/class_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = class_chars[class_labels['interest']==1]\n",
    "negative = class_chars[class_labels['interest']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chars = np.concatenate([positive[:50], negative[:50]], axis=0)\n",
    "train_labels = np.array([1]*50+[0]*50)\n",
    "test_chars = np.concatenate([positive[50:], negative[50:]], axis=0)\n",
    "test_labels = np.array([1]*len(positive[50:])+[0]*len(negative[50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = 'interest_train'\n",
    "TEST_FOLDER = 'interest_test'\n",
    "RATIO = 1/2.6\n",
    "RATIO1 = RATIO/(1+RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch    1,  lr 0.00000, loss 1.28695, smoothed loss 1.28695\n",
      "Batch    2,  lr 0.00000, loss 1.34559, smoothed loss 1.31656\n",
      "Batch    3,  lr 0.00002, loss 1.92772, smoothed loss 1.52441\n",
      "Batch    4,  lr 0.00006, loss 1.05175, smoothed loss 1.40264\n",
      "Batch    5,  lr 0.00025, loss 0.73265, smoothed loss 1.26317\n",
      "Batch    6,  lr 0.00100, loss 0.71026, smoothed loss 1.16630\n",
      "Batch    7,  lr 0.00398, loss 1.49412, smoothed loss 1.21602\n",
      "Batch    8,  lr 0.01585, loss 3.89698, smoothed loss 1.57531\n",
      "Batch    9,  lr 0.06310, loss 1.24476, smoothed loss 1.53554\n",
      "Batch   10,  lr 0.25119, loss 4.11440, smoothed loss 1.81750\n",
      "INFO:tensorflow:Restoring parameters from 107_intent/checkpoints/tmp/model.cpkt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from 107_intent/checkpoints/tmp/model.cpkt\n"
     ]
    }
   ],
   "source": [
    "log_lrs, losses = my_trainer.find_lr_classifier(train_chars, train_labels, 10, 48, [0, 50, 200], init_lr=1e-6, final_lr=1.0, fine_tune_rate=[RATIO,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f35b99d15c0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_title_pos\n",
      "findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/root/anaconda2/envs/tfp/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n",
      "update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xl4VdW9//H3NzMJCYEMhARCIAHCHCCgMihOiHW2WsE6W2n12uH+nOrtr/X2en+9VWvrrVz1UqSoVaiz1lpMHBBQIYQZAoFAIAPkZILM81m/PxIsrUAC2Sf7nH2+r+fheQxnc/bnPMgnO2utvbYYY1BKKeUsAXYHUEopZT0td6WUciAtd6WUciAtd6WUciAtd6WUciAtd6WUciAtd6WUciAtd6WUciAtd6WUcqAgu04cGxtrUlJS7Dq9Ukr5pE2bNlUaY+K6O862ck9JSSE3N9eu0yullE8SkUM9OU6HZZRSyoG03JVSyoG03JVSyoG03JVSyoG03JVSyoG03JVSyoG03JVSyoG03JVSqg898/FeNhyo8vh5tNyVUqqPHKpq4JmP95FTWO3xc2m5K6VUH1m5sZgAgRszh3n8XN2Wu4gsE5FyEdl5itcHiMhfRGSbiOwSkTutj6mUUr6trcPNG7klXJQeT8KAMI+frydX7suB+ad5/V+APGPMZGAu8LSIhPQ+mlJKOccnu8uprG9hwfTkPjlft+VujFkDnG6AyACRIiJA/65j262Jp5RSzrByYxGDo0KZO6bbDR0tYcWY+2JgLHAY2AH82BjjtuB9lVLKEUqPNfH53gpuyhxGUGDfTHVacZbLgK1AIpABLBaRqJMdKCKLRCRXRHIrKiosOLVSSnm/1zcWA/Cd6Z6fSD3OinK/E3jbdCoACoH0kx1ojFlijMk0xmTGxfXNjyZKKWWnDrfh9dxi5oyKY+jA8D47rxXlXgRcDCAig4ExwAEL3lcppXze53vLOVLTzMI+vGqHHjyJSURW0LkKJlZESoDHgGAAY8wLwOPAchHZAQjwiDGm0mOJlVLKh6zIKSa2fwgXjx3cp+ftttyNMQu7ef0wMM+yREop5RDltc18uqec780ZQUhQ394zqneoKqWUh7yxqYQOt+mzte0n0nJXSikPcLsNKzcWcd7IGEbERvT5+bXclVLKA77cX0VxdRMLZvTtROpxWu5KKeUBK3KKiA4P5rLxCbacX8tdKaUsVlXfQlZeGddPGUpYcKAtGbTclVLKYm9tLqGtw7DQpiEZ0HJXSilLGWNYubGYacMHMmpwpG05tNyVUspCOYXVHKhoYEEf35H6z7TclVLKQis3FhMZFsSVkxJtzaHlrpRSFjnW2Mpfdxzh2owk+oXYM5F6nJa7UkpZ5J0tpbS2u21b234iLXellLKAMYaVOcVMGjqA8YkD7I6j5a6UUlbYUnyMfFedLfvInIyWu1JKWWBlThHhIYFcnWHvROpxWu5KKdVLdc1t/GXbEa6enEj/0G53Uu8TWu5KKdVL7287TFNbBwtmeMeQDGi5K6VUr63IKSI9IZLJQ+2fSD1Oy10ppXphZ2kNO0trWTgjGRGxO87XtNyVUqoXVuQUERoUwLUZSXZH+Qda7kopdZYaW9t5b+thrpg4hAHhwXbH+Qda7kopdZY+2H6E+pZ2r5pIPa7bcheRZSJSLiI7T/H6QyKytevXThHpEJFB1kdVSinvsjKniNS4CKanDLQ7yjf05Mp9OTD/VC8aY54yxmQYYzKAR4HPjTHVFuVTSimvlF9Wx+aiY143kXpct+VujFkD9LSsFwIrepVIKaV8wIqcIkICA7h+6lC7o5yUZWPuIhJO5xX+W1a9p1JKeaPmtg7e2VLKvPGDGRQRYneck7JyQvUq4IvTDcmIyCIRyRWR3IqKCgtPrZRSfWfVzjJqmtpY6IUTqcdZWe4L6GZIxhizxBiTaYzJjIuLs/DUSinVd1bkFJE8KJzzRsbYHeWULCl3ERkAXAC8Z8X7KaWUtzpQUc+Gwmpumj6MgADvm0g9rtvty0RkBTAXiBWREuAxIBjAGPNC12HXAVnGmAYP5VRKKa/w543FBAUIN2Z650Tqcd2WuzFmYQ+OWU7nkkmllHKs1nY3b24q4eKx8cRHhtkd57T0DlWllOqh7DwXVQ2tXnlH6j/TcldKqR5aubGIpOh+nD/K+xeEaLkrpVQPFFc3snZfJTdmDiXQiydSj9NyV0qpHvjzxmICBL6TOczuKD2i5a6UUt1o73DzxqZi5o6JJzG6n91xekTLXSmluvFZfgWu2hYWTPeNq3bQcldKqW6tyCkiPjKUi9Lj7Y7SY1ruSil1GkdqmlidX86NmUMJCvSdyvSdpEopZYPXN5bgNnBTpvevbT+RlrtSSp1Ch9vwem4xs9NiSY4JtzvOGdFyV0qpU1i7r4LSY00smOE7E6nHabkrpdQprMwpJiYihHnjEuyOcsa03JVS6iTK65r5eLeLb08bSkiQ71Wl7yVWSqk+8OamEtrdhpt8aG37ibTclVLqn7jdhj9vLGbGiEGkxvW3O85Z0XJXSql/sv5AFYeqGlnogxOpx2m5K6XUP1mxsZiosCAunzDE7ihnTctdKaVOUN3Qykc7y7h+6lDCggPtjnPWtNyVUuoEb28uobXD7ZNr20+k5a6UUl2MMazIKWJKcjTpCVF2x+kVLXellOqSe+go+ysaWDjdt/aRORktd6WU6rIip4j+oUFcOdl3J1KP67bcRWSZiJSLyM7THDNXRLaKyC4R+dzaiEop5Xk1TW18uOMIV2ckEh4SZHecXuvJlftyYP6pXhSRaOA54GpjzHjgRmuiKaVU33lvaynNbW5HDMlAD8rdGLMGqD7NITcDbxtjirqOL7com1JK9YnOidRixidGMXHoALvjWMKKMffRwEARWS0im0TktlMdKCKLRCRXRHIrKiosOLVSSvXe9pIadh+pZeEMZ1y1gzXlHgRMA64ALgN+LiKjT3agMWaJMSbTGJMZFxdnwamVUqr3VuQU0S84kGsyEu2OYhkrZg1KgEpjTAPQICJrgMnAXgveWymlPKq+pZ33tx3myklDiAwLtjuOZay4cn8PmCMiQSISDpwD7LbgfZVSyuP+su0wja0dLHDQkAz04MpdRFYAc4FYESkBHgOCAYwxLxhjdovIKmA74AaWGmNOuWxSKaW8ycqcIkYP7s/U5Gi7o1iq23I3xizswTFPAU9ZkkgppfpI3uFatpXU8IsrxyEidsexlN6hqpTyWys3FhESFMD1U5PsjmI5378NSynl1Z5bXcCr64uYPyGB66YkMT4xyiuukptaO3hnSynfmpBAdHiI3XEsp+WulPIYYwyvbSiiua2Dl786yIvrCkmNi+DajCSunZLEsEHhtmX7644j1DW3O24i9Tgtd6WUx+wpq6PkaBO/vn4i8yck8OGOMt7dWsrT2Xt5Onsv04YP5NqMRK6YlMigiL69el6ZU8TI2AjOGTGoT8/bV7TclVIek7XLhQhcPHYw0eEh3HxOMjefk0zJ0Ube33aYd7eU8vP3dvHLv+Rxweg4rpmSxKVjB9MvxLNPQNrnqiP30FEevTzdK4aIPEHLXSnlMdm7y5iaPJC4yNB/+P2hA8O5b24a916Qyu4jdby3tZT3th7mkz3lRIQEclnX+PzM1FgCA6wv35UbiwkOFL49bajl7+0ttNyVUh5ReqyJnaW1/PTy9FMeIyKMS4xiXGIUD89PZ0NhFe9tOcyHO47w9uZS4iJDuWpSItdNSWJCkjUTsS3tHby9uYRLxw0mtn9o93/AR2m5K6U84uM8FwDzxg3u0fGBAcLM1Fhmpsbyy2vG89mect7dWsqf1h9i2ReFjIyL4LqMJK7JSCI55uwnYj/a5eJoY5ujNgk7GS13pZRHZOe5SI2LYGRc/zP+s2HBgVw+cQiXTxxCTWMbH+48wjtb/j4ROzU5muumJJ3VROyKDUUMG9SPWamxZ5zLl2i5K6UsV9PUxvoDVdxz/shev9eA8GAWzkhm4YxkSo818f7Ws5+IPVjZwFcHqnhw3mgCPDCW70203JVSlludX06723BpD4dkeiopuh/3zk3l3rmp7D5Sy7tbvjkRe21GEjNTYwgK/OYN+Cs3FhMYINyYOczSXN5Iy10pZbmsXS7iIkPJGOq5zbjGDoli7JAoHpmfzobCat7dUsqHO089EdvW4ebNTSVcOCaewVFhHsvlLbTclVKWamnvYHV+OVdnJPXJ0EdAgHBeagznpcbwy2vGszq/nHe2/ONE7LUZSUSGBVFZ38LCGc6/agctd6WUxb7aX0VDa0ePV8lYKSw4kPkThjB/QudE7N+6JmJ/m9357KCEqDAuGO0fT4HTcldKWSorz0V4SCDnpcbYmmNAeDALZiSzoGsi9sPtRxg7JOqkY/FOpOWulLKM2234OM/F3DFxhAV7dguBM5EU3c+SlTu+xD++hTnY5qKjfLan3O4YSgGwvbSG8roWy1fJqDOn5e7DGlraWfRyLne9tJH3tx22O45SZO0qIzBAuGiMlrvdtNx92NK1hVTWtzI6PpIHXt/Kmr0VdkdSfi47z8U5IwYxIDzY7ih+T8vdR1XVt7BkzX4uGz+YN+49j7T4SH7wp01sKTpqdzTlpworG9hXXq9DMl5Cy91HLf6sgKa2Dh66LJ2osGBeums6sf1DuWv5RgrK6+yOp/xQdl4ZgJa7l+i23EVkmYiUi8jOU7w+V0RqRGRr169fWB9Tnai4upFX1xfxncxhpMV3bsoUHxnGK3fPIDAggNtezOHwsSabUyp/k53nYtyQKIYOtO/ReervenLlvhyY380xa40xGV2//qP3sdTp/C57LyLwk0tG/8PvD4+JYPmd06lrbue2ZTkcbWi1KaHyN5X1LeQeOqpX7V6k23I3xqwBqvsgi+qB3UdqeWdrKXfMSiFhwDf3x5iQNIA/3J5JUXUjdy7fSENLuw0plb/5dHc5xsC88Vru3sKqMffzRGSbiPxNRMZb9J7qJJ5ctYfI0CDuuyDtlMecOzKGZxdOYXvJMe59dTOt7e4+TKj8UVZeGUnR/Rg3JMruKKqLFeW+GRhujJkMPAu8e6oDRWSRiOSKSG5FhS7bO1MbDlTxWX4F912Y1u1Ss8vGJ/Bf109kzd4KHnxjG2636aOUyt80trazdl8ll44b7NiHTfuiXpe7MabWGFPf9d8fAsEictJHnBhjlhhjMo0xmXFx/rF5j1WMMfx61R4SosK4Y2ZKj/7MTdOTeXj+GN7fdpj/+CAPY7TglfXW7qukpd1ty0Zh6tR6vbeMiCQALmOMEZEZdH7DqOp1MvUPsvJcbCk6xq+vn3hGe3bce0EqVfWtvLiukNj+Idx/0SgPplT+KGuXi6iwIKaPGGR3FHWCbstdRFYAc4FYESkBHgOCAYwxLwA3APeKSDvQBCwweoloqfYON0+u2kNqXAQ3TBt6Rn9WRPjZt8ZS3dDKb7L2MjAihO+eM9xDSZW/ae9w8+keFxePHUywn+y26Cu6LXdjzMJuXl8MLLYskfqGtzaXsL+igRdumXpW25UGBAhP3jCJY42t/N93dzIwPIRvTRzigaTK32w6dJSjjW26BNIL6bdaL9fc1sHvsveRMSyay8YnnPX7BAcG8Nx3pzE1eSA/WbmVLwsqLUyp/FVWnouQwADO95MHYPgSLXcv99KXBymrbeanl6f3eiVCv5BAXrw9k5TYcO55OZcdJTUWpVT+yBhDdp6LWWkx9A/VR0N4Gy13L1bT2MZzq/czd0wc54605qk20eEhvHzXOUSHh3DHH3MorGyw5H2V/8l31VFU3cil487+J0rlOVruXuz5z/dT29zGw5elW/q+CQM696ExwK0vbsBV22zp+yv/kL3LhQhcMi7e7ijqJLTcvVRZTTN//KKQayYnMi7R+rv+Rsb1Z/md0zna0MptL+ZQ09hm+TmUs2XvdpExLJr4yG9ug6Hsp+Xupf77k724jeGBeWM8do5JQ6NZclsmhZUN3P3SRppaOzx2LuUsR2qa2F5So6tkvJiWuxcqKK/n9dwSvnvOcIYN8uz2qbPSYvndTRlsKjrKv7y2mbYO3YdGde/jPBcA83S83WtpuXuh33yUT1hQAPdfdOrNwax0xaQhPH7NBD7dU84jb23XfWhUt7LyXIyMjfj6eQLK++j6JS+zpegoq3aV8ZNLRhHbP7TPznvLucOpbmjlt9l7iYkI4d++NVY3gVInVdvcxvoDVdw1e4TdUdRpaLl7EWMMT6zaQ2z/EL43Z2Sfn/+HF6VRVd/CH9YWEtM/lB9ckNrnGZT3W51fQVuH0Y3CvJyWuxf5fG8F6w9U88urx9tyU4iI8NhV46lubOPXf9vDoPAQvjN9WJ/nUN4ta1cZsf1DyBg20O4o6jS03L2E2214YlU+yYPCWTgj2bYcAQHC0zdO5lhjKz99ezsDI0J0RYT6Wmu7m8/zK7hi0hACA3TYzpvphKqXeH/bYXYfqeWBeaMJCbL3ryUkKIAXbpnGxKHR3P/aZjYc0B2cVaf1B6qoa2nXb/g+QMvdC7S2u3k6O59xQ6K4alKi3XEAiAgN4o93TGfowH5876Vc8g7X2h1JeYGsvDL6BQcyK+2kz+NRXkTL3Qu8tuEQxdVNPHJ5OgFe9KPuoIgQXr77HPqHBXHbshyKqhrtjqRs5HYbPs4r54LRcWf0wBhlDy13m9W3tPPspwWcNzKG80d539VQUnQ/Xr5rBu1uN7cu20B5ne5D4692lNZQVtusQzI+QsvdZkvXHqCqoZVHLNjS11NGDY5k2R3TKa9t4Y5lG6lt1n1o/FF2novAAOGidN0ozBdouduosr6FP6w5wOUTEsgYFm13nNOamjyQ52+Zyl5XHfe8lEtzm+5D42+y81xMTxnIwIgQu6OoHtByt9HiTwtobnfz4GWe2xzMSnPHxPP0dyazobCaH63YQrvuQ+M3DlU1kO+q073bfYiWu02Kqhp5dcMhvpM5jNQ439mf45qMJB67ahxZeS5+9s5O9Fno/iH7643CdLzdV+hNTDb5bXY+gQHCTy4ZZXeUM3bnrBFUN7Ty7KcFxPQP4eH51j5MRHmfrDwX6QmRHt+lVFmn2yt3EVkmIuUisrOb46aLSIeI3GBdPGfadbiG97Yd5s5ZIxgc5ZsPOvg/l47m5nOSeW71fpauPWB3HOVB1Q2t5B6s1qt2H9OTYZnlwPzTHSAigcATwEcWZHK8J1flExUW7NMbc4kIj18zgcsnJPCff93NO1tK7I6kPOST3S7cBuaN1/F2X9JtuRtj1gDV3Rz2Q+AtoNyKUE721f4qPt9bwX1zUxnQL9juOL0SGCA8syCDmakxPPTGdj7L179+J8rKc5E4IIzxHnjco/KcXk+oikgScB3wQu/jOJsxhl+v2sOQAWHcPjPF7jiWCA0K5H9vncbowZH86LUt7K+otzuSslBTawdr91Vw6bjBXnsfhjo5K1bLPAM8YozpduGziCwSkVwRya2oqLDg1L7lo11lbCs+xr9eMtpRt29HhgXzh9szCQ4KYNHLudTpTU6Osa6gkuY2ty6B9EFWlHsmsFJEDgI3AM+JyLUnO9AYs8QYk2mMyYyLi7Pg1L6jvcPNkx/lkxbfn+unJtkdx3JJ0f1YfPMUDlY18sDr2/RRfQ6RtauMyLAgzhk5yO4o6gz1utyNMSOMMSnGmBTgTeA+Y8y7vU7mMG9sKuFARQMPXTaGoEBn3l4wMzWWf/vWWLLyXPzPZwV2x1G91OE2fLKnnIvS4wl26P+zTtbtOncRWQHMBWJFpAR4DAgGMMboOHsPNLV28MzHe5maHO345WR3zUphZ2kNv/14L+OTorgo3dmf18k2HTpKdUOrbhTmo7otd2PMwp6+mTHmjl6lcajlXx7EVdvCswunOn5SSkT41XUT2euq48crtvLe/bMY6UN34Kq/y84rIzhQuGC0fw2hOoX+rOVhxxpbeX51ARelxzNjhH+MW/YL6VxBExQofP+VTdS3tNsdSZ0hYwxZeS5mpsYSGebbS3b9lZa7hz2/ej91Le08PN83NgezytCB4fzPzVM5UNnAA69v1QlWH7OvvJ5DVY06JOPDtNw96EhNE8u/PMh1GUmkJ/jfDSAz02J59PJ0Ptrl4rnVOsHqS45vFKbl7ru03D3omex9GAP/eulou6PY5u7ZI7g2I5Gns/fy6R6X3XFUD2XluZg8LNpn9z5SWu4eU1Bexxubirnl3OF+vZOeiPBf109ibEIUP165lcLKBrsjqW64apvZVnzM8Su7nE7L3UOe+iif8JAg7r8oze4otvt6gjVAWPRyrk6wejndu90ZtNw9YNOho3y0y8Wi80cySB9JBsCwQeEsvnkq+yvqefD1bfqQDy+WleciJSactHhdwurLtNwtZozhiVV7iO0fyt2zR9gdx6vMSovl0cvHsmpXGc+t3m93HHUSdc1tfLW/knnjExx/T4bTablbbHV+BTmF1fz44jQiQvVBV//se3NGcPXkRH6Tla9bBHuhz/dW0NZhdJWMA2i5W8jt7rxqHx4TzoIZyXbH8UoiwhPfnkR6QhQ/XrGFgzrB6lWydrmIiQhhavJAu6OoXtJyt9B720rZU1bHA/PG6EZLp9EvJJAlt04jIEBY9EouDTrB6hVa2918ll/OxWPjCQzQIRlfpw1kkZb2Dn7z0V7GJ0Zx5cQhdsfxesMGhbN44VQKyut56E2dYPUGGwqrqGtu173bHULL3SKvri+i9FgTj8xPJ0Cvenpk9qhYfnp5Oh/uKOP5z3WC1W7ZeS7CggOYnRZrdxRlAS13C9Q1t7H4swJmpcUwZ5T+wzgT98wZyVWTE3nqo3xW6wSrbYwxZOe5OH9UHP1CnPOUMH+m5W6BP6wtpLqhlUfmp+vysTPUOcE6kTGDI/nRii0cqtIJVjvsLK3lSE2zrpJxEC33Xqqoa2Hp2gNcMXEIk4ZG2x3HJ4WHBLHk1kxEhEUvb9IJVhtk55URIHDxWC13p9By76VnP91HS7ubB+b57+ZgVkiOCWfxzVPYV17Hw29u1wnWPpaV5yIzZZDeUe0gWu69cKiqgdc2FHHT9GH6tCELzBkVx8Pz0/nrjiO88PkBu+P4jeLqRvaU1eleMg6j5d4LT2ftJTgwgJ9cPMruKI7x/fNHcsWkITz50R4+31thdxy/kKV7tzuSlvtZaGrt4IPth3l/22Hump1CvO55bRkR4akbJukEax/K2lXGmMGRDI+JsDuKspBuftID7R1udpTW8EVBJesKKtl86BitHW4SB4Tx/QtS7Y7nOOEhQfzvrdO4evEXfP+VTbx930zCQ/R/VU842tDKxoPV3DdXt6Z2Gv0XcxLGGA5UNnSW+b5KvjrQeecewLghUdwxK4VZabHMSBmka4I9ZHhMBL9fOIU7/5jDQ29uZ/HCKbrM1AM+3VOO28C88Tok4zTdlruILAOuBMqNMRNO8vo1wOOAG2gHfmKMWWd1UE8rr2vmy4Iq1hVU8kVBJUdqmgFIiu7HFROHMCstlpmpMcT0D7U5qf+4YHQcD12WzhOr9jApaYD+lOQBWXllJESFMTFpgN1RlMV6cuW+HFgMvHyK1z8B3jfGGBGZBLwOpFsTz3MaWtrJKaxmXdfVeb6rDoAB/YKZlRbD/WmxzE6LJXlQuF4x2ugHF4xkZ2kNT6zaw7jEKOaMirM7kmM0t3WwZm8lN0wbqv+PO1C35W6MWSMiKad5vf6ELyMAr1yg3NbhZnvJMdbtq+KLgko2Fx2l3W0ICQpgRsogrp2SxOy0WMYlRumOeF5ERHjyhkkUlNdz/2tb+Mv9s0mO8d9n0lpp3b5Kmto6dJWMQ1ky5i4i1wH/BcQDV5zmuEXAIoDkZM/ud26MoaC8/uthlvUHqqlvaUcEJiYN4J7zRzI7LZZpwwcSFqzj5t4sIjSIJbdN46pn17HolVydYLVIdp6LyNAgzh0ZY3cU5QGW/AsxxrwDvCMi59M5/n7JKY5bAiwByMzMtPwKv6ymmS+6ynxdQSXldS0ApMSEc01GIrPTYjkvNYbocL0Lz9d8PcG6fCOPvLWD3y/I0KGEXuhwGz7Z42JuejwhQboi2oksvfzpGsJJFZFYY0ylle99MrXNbWw4UP11mReUd44QDYoIYVZaLLPTYpiZGsuwQfpjvBPMHRPPg/PG8NRH+UxMimLR+TrBera2FB2lsr5Vh2QcrNflLiJpwP6uCdWpQAhQ1etkp3Cgop53t5SyrqCSbSU1dLgNYcEBnDMihpsyhzErLZb0hEjdU92h7pubyq7DNfz6b3sYN2QAs3WL5bOSneciOFCYO0YnqJ2qJ0shVwBzgVgRKQEeA4IBjDEvAN8GbhORNqAJuMl4cNen/RUNLP6sgElDo7n3glRmpcUydXg0oUE6bu4POu9gndw5wbpiM3+5f7b+ZHaGjDFk5bk4d2QMUWHBdsdRHiJ27b6XmZlpcnNzz/jPNbd10NLuZkA//Z/Snx2sbODqxetIGhjO2/fO1JvJzkBBeR2X/HYNj18znlvPS7E7jjpDIrLJGJPZ3XE+N5MSFhyoxa5IiY3gvxdOYU9ZLY+8pVsEn4njG4VdouPtjuZz5a7UcRd2TbC+v+0wL64rtDuOz8ja5WLS0AEMGdDP7ijKg7TclU+7b24q88cn8KsPd/NFgccXaPm88tpmthYf41J94pLjabkrnyYi/OY7k0mN68/9r22muLrR7khe7ePdnQ8hnzc+weYkytO03JXP6x8axJLbMml3G77/yiaaWjvsjuS1svLKSB4UzujB+uQwp9NyV44wIjaC3y+Ywu6yWm7/Yw7HGlvtjuR16lva+bKgikvHDda7e/2AlrtyjAvT43nmpgy2Fh3j+ue/pKhKh2hO9Hl+Ba0dbn1Wqp/QcleOck1GEq/cPYOq+laue+4LthYfszuS18jOK2NgeDDThg+0O4rqA1ruynHOGRnTuXNkaCALlnzFqp1ldkeyXVuHm0/3lHPx2MEEBeo/e3+gf8vKkVLj+vPOfbMYkxDFva9u8vt18DmF1dQ2t+tGYX5Ey105Vmz/UFbecy7zxg3m8Q/y+Pf3d9Hh9s87WbPzXIQGBTBHN1rzG1ruytH6hQTy3HencdesESz/8iD3/smOhdSnAAAI60lEQVT/lkoaY8jOczFnVJw+5MSPaLkrxwsMEH5x1Tgeu2oc2btdLFjyFRVdD3LxB7sO11J6rElXyfgZLXflN+6cNYL/vWUa+a46rn/+i68f7uJ02XkuAgQuHhtvdxTVh7TclV+ZNz6BlYvOo6m1g+uf+4L1Bzz2XBmvkZXnYtrwgcT0D7U7iupDWu7K72QMi+ad+2YRFxnKbS/m8N7WUrsjeUxxdSO7j9TqKhk/pOWu/NKwQeG8fe8spiRH8+OVW1n86T5H7gn/8e7OvdsvHacbhfkbLXfltwaEB/Py3TO4NiOR32Tt5dG3d9DW4bY7lqWydrkYFd+fEbERdkdRfUzLXfm10KBAfndTBj+8KI2VG4u5a/lG6prb7I5liWONreQcrNYhGT+l5a78nojwwLwxPPHtiXy5v4obX/iKIzVNdsfqlV2Ha3jkre10uI3u3e6n9I4GpbrcND2ZIQP6cd+rm7n2f75g2R3TGZ84wO5YPeZ2G1bvLWfp2kK+3F9FeEgg981NZfJQ3/kMyjrS3SSSiCwDrgTKjTETTvL6d4FHur6sB+41xmzr7sSZmZkmNzf3zBMr5WG7j9Ry5x87h2eeu2UaF4yOszvSaTW3dfDW5hJeXFfIgYoGhgwI446ZKSyYkawPk3cgEdlkjMns9rgelPv5dJb2y6co95nAbmPMURG5HPh3Y8w53Z1Yy115s7KaZu5cvpG9rjr+89oJLJyRbHekbyiva+ZPXx3iTxuKqG5oZUJSFPfMGcm3Jg4hWHd+dKyelnu3wzLGmDUiknKa17884cv1wNCeBFTKmyUMCOONH5zHv7y6mUff3kFxdSMPzhtDQID9TzDKL6tj6doDvLf1MG1uNxenD+aeOSOYMWKQPmFJfc3qMfe7gb9Z/J5K2aJ/aBBLb8/kF+/t5LnV+yk52sRTN04iNCiwz7MYY1izr5Klaw+wdl8lYcEB3DR9GHfOSmFknD4PVX2TZeUuIhfSWe6zT3PMImARQHKy9/2Yq9Q/Cw4M4FfXTWTYoHCeXJVPWU0zS26bRnR4SJ+cv7mtg/e3HmbpugPsddUTHxnKQ5eN4eYZyQyM6JsMyjd1O+YO0DUs88HJxty7Xp8EvANcbozZ25MT65i78jXvbzvMg69vY+igfiy/YwbJMeEeO1dVfQt/Wl/EK+sPUlnfSnpCJPfMGclVkxMJCdLxdH9m2Zh7D06UDLwN3NrTYlfKF109OZGEqDDueTmX6577gqW3ZzIl2drnkRaU1/HiuoO8vbmElnY3F46J4545IzkvNUbH09UZ6clqmRXAXCAWcAGPAcEAxpgXRGQp8G3gUNcfae/JdxW9cle+an9FPXf8MYeKuhaeuWkK8yf07iYhYwxf7q9i6doDfJZfQWhQANdPHcrds1NIi4+0KLVyCsuWQnqKlrvyZZX1LXzvpVy2lRzj/14xjrtnjzjj92htd/OXbYdZuq6Q3Udqie0fwq3npnDLucm6Pa86pT4bllHKH8X2D2XFPefykz9v4fEP8iiubuTnV44jsAdLJY81tvLqhiJe+vIg5XUtjB7cnye/PYmrMxIJC+77lTjKmbTclTpLx5/P+qsPd/PiukJKjzXx+wVT6Bdy8oIurGxg2bpC3txUQlNbB3NGxfLUjZM5f1Ssjqcry2m5K9ULgQHCz68cx7CB/fjlB3ksWPIVS2+fTlxk57CKMYYNhdUsXVvIJ3tcBAcEcE1GInfPGUF6QpTN6ZWTabkrZYE7Zo0gMbofP1q55euVNJ13khayo7SGgeHB/PDCNG45bzjxkWF2x1V+QCdUlbLQtuJj3P3SRirrWwEYGRfB3bNHcP2UoaccrlHqTOiEqlI2mNz1fNbnP9/PxenxXDgm3iv2o1H+R8tdKYsNGxTOr66baHcM5ef0PmallHIgLXellHIgLXellHIgLXellHIgLXellHIgLXellHIgLXellHIgLXellHIg27YfEJEK/v6AjzMVC1RaGMcbOf0zOv3zgfM/o34+eww3xsR1d5Bt5d4bIpLbk70VfJnTP6PTPx84/zPq5/NuOiyjlFIOpOWulFIO5KvlvsTuAH3A6Z/R6Z8PnP8Z9fN5MZ8cc1dKKXV6vnrlrpRS6jR8utxF5Iciki8iu0TkSbvzWE1E/l1ESkVka9evb9mdyRNE5EERMSISa3cWK4nI4yKyvevvLktEEu3OZDUReUpE9nR9zndEJNruTFYSkRu7+sUtIj61csZny11ELgSuASYZY8YDv7E5kqf8zhiT0fXrQ7vDWE1EhgGXAkV2Z/GAp4wxk4wxGcAHwC/sDuQB2cAEY8wkYC/wqM15rLYTuB5YY3eQM+Wz5Q7cC/zaGNMCYIwptzmPOju/Ax4GHDf5Y4ypPeHLCJz5GbOMMe1dX64HhtqZx2rGmN3GmHy7c5wNXy730cAcEdkgIp+LyHS7A3nI/V0/8i4TkYF2h7GSiFwNlBpjttmdxVNE5P+JSDHwXZx55X6iu4C/2R1CdfLqZ6iKyMdAwkle+hmd2QcC5wLTgddFZKTxseU/3XzG54HH6bziexx4ms5/QD6jm8/3b8C8vk1krdN9PmPMe8aYnwE/E5FHgfuBx/o0oAW6+4xdx/wMaAde7ctsVujJ5/NFPrsUUkRW0Tkss7rr6/3AucaYCluDeYiIpAAfGGMm2BzFEiIyEfgEaOz6raHAYWCGMabMtmAeIiLDgb865e/vRCJyO/AD4GJjTGN3x/siEVkNPGiMybU7S0/58rDMu8BFACIyGgjBOzf5OWsiMuSEL6+jc3LHEYwxO4wx8caYFGNMClACTHVSsYvIqBO+vBrYY1cWTxGR+cAjwNVOLXZf5ctX7iHAMiADaKXzu+qn9qayloi8QufnM8BB4PvGmCO2hvIQETkIZBpjHPMNWkTeAsYAbjp3QP2BMabU3lTWEpECIBSo6vqt9caYH9gYyVIich3wLBAHHAO2GmMuszdVz/hsuSullDo1Xx6WUUopdQpa7kop5UBa7kop5UBa7kop5UBa7kop5UBa7kop5UBa7kop5UBa7kop5UD/H5TokzBdlBiXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(log_lrs, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for _ in range(10):\n",
    "#     my_trainer.train_step_classifier(train_chars, train_labels, 6, 3e-4, 20, [0, 50, 200], fine_tune_rate=[0, 0, 0, 0], folder_name=TRAIN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for _ in range(10):\n",
    "#     my_trainer.train_step_classifier(train_chars, train_labels, 10, 3e-4, 20, [0, 50, 200], fine_tune_rate=[RATIO, 0, 0, 0], folder_name=TRAIN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for _ in range(10):\n",
    "#     my_trainer.train_step_classifier(train_chars, train_labels, 10, 3e-4, 20, [0, 50, 200], fine_tune_rate=[RATIO, RATIO*RATIO, 0, 0], folder_name=TRAIN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for _ in range(10):\n",
    "#     my_trainer.train_step_classifier(train_chars, train_labels, 10, 3e-4, 20, [0, 50, 200], fine_tune_rate=[RATIO, RATIO*RATIO, RATIO*RATIO*RATIO, 0], folder_name=TRAIN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(10):\n",
    "# my_trainer.train_step_classifier(train_chars, train_labels, 6, 3e-4, 20, [0, 50, 200], fine_tune_rate=[1/2.6, 1/2.6, 1/2.6, 1/2.6], folder_name='class_train_180')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 15\n",
    "BATCH_SIZE = 10\n",
    "TOTAL_ITER = NUM_EPOCH * len(train_labels)/BATCH_SIZE\n",
    "LR_MAX = 1e-3\n",
    "LR_RATIO = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step    1: loss: 0.88038, acc: 0.70000, bptt:  52, time 03.86\n",
      "Step    2: loss: 1.01360, acc: 0.60000, bptt:  40, time 03.98\n",
      "Step    3: loss: 0.90978, acc: 0.70000, bptt:  44, time 04.17\n",
      "Step    4: loss: 0.86955, acc: 0.50000, bptt:  44, time 04.32\n",
      "Step    5: loss: 0.68284, acc: 0.60000, bptt:  46, time 04.44\n",
      "Step    6: loss: 0.58446, acc: 0.70000, bptt:  45, time 04.58\n",
      "Step    7: loss: 0.79076, acc: 0.50000, bptt:  48, time 04.76\n",
      "Step    8: loss: 0.57848, acc: 0.70000, bptt:  47, time 04.89\n",
      "Step    9: loss: 0.66445, acc: 0.60000, bptt:  23, time 05.07\n",
      "Step   10: loss: 0.71952, acc: 0.40000, bptt:  42, time 05.37\n",
      "Step   11: loss: 0.47029, acc: 0.90000, bptt:  50, time 00.21\n",
      "Step   12: loss: 0.43925, acc: 0.90000, bptt:  50, time 00.37\n",
      "Step   13: loss: 0.70450, acc: 0.30000, bptt:  55, time 00.54\n",
      "Step   14: loss: 0.54110, acc: 0.80000, bptt:  41, time 00.73\n",
      "Step   15: loss: 0.47494, acc: 0.70000, bptt:  44, time 00.98\n",
      "Step   16: loss: 0.89166, acc: 0.50000, bptt:  47, time 01.11\n",
      "Step   17: loss: 0.40615, acc: 0.80000, bptt:  50, time 01.25\n",
      "Step   18: loss: 0.75182, acc: 0.80000, bptt:  52, time 01.40\n",
      "Step   19: loss: 0.69222, acc: 0.80000, bptt:  54, time 01.54\n",
      "Step   20: loss: 0.40265, acc: 0.80000, bptt:  50, time 01.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Ignoring: 107_intent/checkpoints/tmp; No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring: 107_intent/checkpoints/tmp; No such file or directory\n",
      "Step   21: loss: 0.25397, acc: 0.90000, bptt:  51, time 00.29\n",
      "Step   22: loss: 0.75978, acc: 0.50000, bptt:  43, time 00.42\n",
      "Step   23: loss: 0.23953, acc: 0.90000, bptt:  42, time 00.56\n",
      "Step   24: loss: 0.10402, acc: 1.00000, bptt:  43, time 00.68\n",
      "Step   25: loss: 0.46088, acc: 0.70000, bptt:  39, time 00.81\n",
      "Step   26: loss: 0.84189, acc: 0.70000, bptt:  40, time 01.04\n",
      "Step   27: loss: 0.54839, acc: 0.70000, bptt:  47, time 01.19\n",
      "Step   28: loss: 0.31973, acc: 0.80000, bptt:  44, time 01.32\n",
      "Step   29: loss: 0.12932, acc: 1.00000, bptt:  25, time 01.50\n",
      "Step   30: loss: 0.31956, acc: 0.80000, bptt:  46, time 01.65\n",
      "Step   31: loss: 0.09444, acc: 1.00000, bptt:  57, time 00.15\n",
      "Step   32: loss: 0.18134, acc: 0.90000, bptt:  46, time 00.27\n",
      "Step   33: loss: 0.03416, acc: 1.00000, bptt:  54, time 00.41\n",
      "Step   34: loss: 0.02104, acc: 1.00000, bptt:  47, time 00.57\n",
      "Step   35: loss: 0.06575, acc: 1.00000, bptt:  51, time 00.72\n",
      "Step   36: loss: 0.02705, acc: 1.00000, bptt:  48, time 00.87\n",
      "Step   37: loss: 0.05802, acc: 1.00000, bptt:  55, time 01.01\n",
      "Step   38: loss: 0.15368, acc: 0.90000, bptt:  13, time 01.21\n",
      "Step   39: loss: 0.05846, acc: 1.00000, bptt:  53, time 01.35\n",
      "Step   40: loss: 0.01822, acc: 1.00000, bptt:  44, time 01.63\n",
      "Step   41: loss: 0.08986, acc: 0.90000, bptt:  44, time 00.13\n",
      "Step   42: loss: 0.00870, acc: 1.00000, bptt:  43, time 00.28\n",
      "Step   43: loss: 0.00919, acc: 1.00000, bptt:  46, time 00.45\n",
      "Step   44: loss: 0.01623, acc: 1.00000, bptt:  54, time 00.58\n",
      "Step   45: loss: 0.03644, acc: 1.00000, bptt:  45, time 00.73\n",
      "Step   46: loss: 0.01317, acc: 1.00000, bptt:  49, time 00.85\n",
      "Step   47: loss: 0.00247, acc: 1.00000, bptt:  55, time 01.00\n",
      "Step   48: loss: 0.00448, acc: 1.00000, bptt:  53, time 01.11\n",
      "Step   49: loss: 0.00268, acc: 1.00000, bptt:  39, time 01.25\n",
      "Step   50: loss: 0.00319, acc: 1.00000, bptt:  45, time 01.53\n",
      "Step   51: loss: 0.00127, acc: 1.00000, bptt:  41, time 00.26\n",
      "Step   52: loss: 0.00116, acc: 1.00000, bptt:  52, time 00.41\n",
      "Step   53: loss: 0.03738, acc: 1.00000, bptt:  45, time 00.55\n",
      "Step   54: loss: 0.00025, acc: 1.00000, bptt:  49, time 00.68\n",
      "Step   55: loss: 0.00032, acc: 1.00000, bptt:  51, time 00.83\n",
      "Step   56: loss: 0.01001, acc: 1.00000, bptt:  52, time 00.95\n",
      "Step   57: loss: 0.00013, acc: 1.00000, bptt:  47, time 01.11\n",
      "Step   58: loss: 0.00436, acc: 1.00000, bptt:  49, time 01.25\n",
      "Step   59: loss: 0.00036, acc: 1.00000, bptt:  50, time 01.38\n",
      "Step   60: loss: 0.00215, acc: 1.00000, bptt:  42, time 01.52\n",
      "Step   61: loss: 0.00888, acc: 1.00000, bptt:  44, time 00.21\n",
      "Step   62: loss: 0.00046, acc: 1.00000, bptt:  45, time 00.36\n",
      "Step   63: loss: 0.00174, acc: 1.00000, bptt:  49, time 00.51\n",
      "Step   64: loss: 0.00003, acc: 1.00000, bptt:  50, time 00.62\n",
      "Step   65: loss: 0.00001, acc: 1.00000, bptt:  47, time 00.78\n",
      "Step   66: loss: 0.00025, acc: 1.00000, bptt:  42, time 00.90\n",
      "Step   67: loss: 0.00166, acc: 1.00000, bptt:  49, time 01.06\n",
      "Step   68: loss: 0.00001, acc: 1.00000, bptt:  52, time 01.18\n",
      "Step   69: loss: 0.00001, acc: 1.00000, bptt:  53, time 01.30\n",
      "Step   70: loss: 0.12247, acc: 0.90000, bptt:  47, time 01.42\n",
      "Step   71: loss: 0.00001, acc: 1.00000, bptt:  42, time 00.14\n",
      "Step   72: loss: 0.00004, acc: 1.00000, bptt:  46, time 00.27\n",
      "Step   73: loss: 0.00003, acc: 1.00000, bptt:  49, time 00.39\n",
      "Step   74: loss: 0.00005, acc: 1.00000, bptt:  45, time 00.52\n",
      "Step   75: loss: 0.00009, acc: 1.00000, bptt:  52, time 00.67\n",
      "Step   76: loss: 0.00033, acc: 1.00000, bptt:  28, time 00.83\n",
      "Step   77: loss: 0.00031, acc: 1.00000, bptt:  55, time 00.97\n",
      "Step   78: loss: 0.00359, acc: 1.00000, bptt:  43, time 01.21\n",
      "Step   79: loss: 0.00008, acc: 1.00000, bptt:  45, time 01.36\n",
      "Step   80: loss: 0.00011, acc: 1.00000, bptt:  41, time 01.58\n",
      "Step   81: loss: 0.00081, acc: 1.00000, bptt:  52, time 00.30\n",
      "Step   82: loss: 0.00002, acc: 1.00000, bptt:  26, time 00.47\n",
      "Step   83: loss: 0.00001, acc: 1.00000, bptt:  49, time 00.60\n",
      "Step   84: loss: 0.00089, acc: 1.00000, bptt:  26, time 00.80\n",
      "Step   85: loss: 0.00006, acc: 1.00000, bptt:  45, time 00.92\n",
      "Step   86: loss: 0.00021, acc: 1.00000, bptt:  51, time 01.07\n",
      "Step   87: loss: 0.00001, acc: 1.00000, bptt:  47, time 01.19\n",
      "Step   88: loss: 0.00002, acc: 1.00000, bptt:  47, time 01.33\n",
      "Step   89: loss: 0.00004, acc: 1.00000, bptt:  46, time 01.47\n",
      "Step   90: loss: 0.00061, acc: 1.00000, bptt:  52, time 01.63\n",
      "Step   91: loss: 0.00000, acc: 1.00000, bptt:  47, time 00.15\n",
      "Step   92: loss: 0.00007, acc: 1.00000, bptt:  44, time 00.28\n",
      "Step   93: loss: 0.00007, acc: 1.00000, bptt:  45, time 00.39\n",
      "Step   94: loss: 0.00009, acc: 1.00000, bptt:  50, time 00.52\n",
      "Step   95: loss: 0.00002, acc: 1.00000, bptt:  53, time 00.68\n",
      "Step   96: loss: 0.00004, acc: 1.00000, bptt:  53, time 00.83\n",
      "Step   97: loss: 0.00021, acc: 1.00000, bptt:  43, time 00.97\n",
      "Step   98: loss: 0.00012, acc: 1.00000, bptt:  53, time 01.10\n",
      "Step   99: loss: 0.00001, acc: 1.00000, bptt:  31, time 01.27\n",
      "Step  100: loss: 0.00010, acc: 1.00000, bptt:  49, time 01.54\n",
      "Step  101: loss: 0.00059, acc: 1.00000, bptt:  50, time 00.14\n",
      "Step  102: loss: 0.00001, acc: 1.00000, bptt:  51, time 00.27\n",
      "Step  103: loss: 0.00004, acc: 1.00000, bptt:  47, time 00.42\n",
      "Step  104: loss: 0.01557, acc: 1.00000, bptt:  51, time 00.56\n",
      "Step  105: loss: 0.00006, acc: 1.00000, bptt:  45, time 00.69\n",
      "Step  106: loss: 0.00068, acc: 1.00000, bptt:  13, time 00.96\n",
      "Step  107: loss: 0.00116, acc: 1.00000, bptt:  47, time 01.08\n",
      "Step  108: loss: 0.00070, acc: 1.00000, bptt:  54, time 01.22\n",
      "Step  109: loss: 0.00030, acc: 1.00000, bptt:  41, time 01.40\n",
      "Step  110: loss: 0.00020, acc: 1.00000, bptt:  51, time 01.62\n",
      "Step  111: loss: 0.00000, acc: 1.00000, bptt:  51, time 00.14\n",
      "Step  112: loss: 0.00008, acc: 1.00000, bptt:  47, time 00.28\n",
      "Step  113: loss: 0.00004, acc: 1.00000, bptt:  32, time 00.49\n",
      "Step  114: loss: 0.00001, acc: 1.00000, bptt:  44, time 00.67\n",
      "Step  115: loss: 0.00000, acc: 1.00000, bptt:  45, time 00.81\n",
      "Step  116: loss: 0.00004, acc: 1.00000, bptt:  46, time 00.94\n",
      "Step  117: loss: 0.00005, acc: 1.00000, bptt:  52, time 01.07\n",
      "Step  118: loss: 0.00019, acc: 1.00000, bptt:  44, time 01.22\n",
      "Step  119: loss: 0.00012, acc: 1.00000, bptt:  45, time 01.36\n",
      "Step  120: loss: 0.00008, acc: 1.00000, bptt:  52, time 01.58\n",
      "Step  121: loss: 0.00001, acc: 1.00000, bptt:  44, time 00.22\n",
      "Step  122: loss: 0.00002, acc: 1.00000, bptt:  52, time 00.36\n",
      "Step  123: loss: 0.00000, acc: 1.00000, bptt:  54, time 00.50\n",
      "Step  124: loss: 0.00001, acc: 1.00000, bptt:  53, time 00.63\n",
      "Step  125: loss: 0.00002, acc: 1.00000, bptt:  43, time 00.74\n",
      "Step  126: loss: 0.00002, acc: 1.00000, bptt:  45, time 00.86\n",
      "Step  127: loss: 0.00037, acc: 1.00000, bptt:  56, time 01.00\n",
      "Step  128: loss: 0.00001, acc: 1.00000, bptt:  21, time 01.20\n",
      "Step  129: loss: 0.00002, acc: 1.00000, bptt:  53, time 01.36\n",
      "Step  130: loss: 0.00006, acc: 1.00000, bptt:  42, time 01.50\n",
      "Step  131: loss: 0.00008, acc: 1.00000, bptt:  50, time 00.22\n",
      "Step  132: loss: 0.00000, acc: 1.00000, bptt:  47, time 00.35\n",
      "Step  133: loss: 0.00001, acc: 1.00000, bptt:  52, time 00.46\n",
      "Step  134: loss: 0.00001, acc: 1.00000, bptt:  33, time 00.59\n",
      "Step  135: loss: 0.00000, acc: 1.00000, bptt:  49, time 00.74\n",
      "Step  136: loss: 0.00026, acc: 1.00000, bptt:  51, time 00.88\n",
      "Step  137: loss: 0.00003, acc: 1.00000, bptt:  50, time 01.04\n",
      "Step  138: loss: 0.00003, acc: 1.00000, bptt:  45, time 01.19\n",
      "Step  139: loss: 0.00002, acc: 1.00000, bptt:  52, time 01.32\n",
      "Step  140: loss: 0.00002, acc: 1.00000, bptt:  55, time 01.47\n",
      "Step  141: loss: 0.00020, acc: 1.00000, bptt:  44, time 00.13\n",
      "Step  142: loss: 0.00004, acc: 1.00000, bptt:  47, time 00.28\n",
      "Step  143: loss: 0.00054, acc: 1.00000, bptt:  51, time 00.40\n",
      "Step  144: loss: 0.00007, acc: 1.00000, bptt:  21, time 00.57\n",
      "Step  145: loss: 0.00002, acc: 1.00000, bptt:  53, time 00.73\n",
      "Step  146: loss: 0.00000, acc: 1.00000, bptt:  51, time 00.86\n",
      "Step  147: loss: 0.00000, acc: 1.00000, bptt:  49, time 00.99\n",
      "Step  148: loss: 0.00004, acc: 1.00000, bptt:  47, time 01.13\n",
      "Step  149: loss: 0.00004, acc: 1.00000, bptt:  47, time 01.27\n",
      "Step  150: loss: 0.00002, acc: 1.00000, bptt:  46, time 01.54\n"
     ]
    }
   ],
   "source": [
    "lr = slanted_triangular_learning_rate(TOTAL_ITER, 1/NUM_EPOCH, LR_MAX, LR_RATIO)\n",
    "for _ in range(NUM_EPOCH):\n",
    "    my_trainer.train_step_classifier(train_chars, train_labels, BATCH_SIZE, lr, 48, [0, 50, 200], fine_tune_rate=[RATIO, RATIO1, RATIO1, RATIO], folder_name=TRAIN_FOLDER)\n",
    "#     lr = max(lr * 0.4, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for _ in range(10):\n",
    "#     my_trainer.train_step_classifier(train_chars, train_labels, 12, lr, 20, [0, 50, 200], fine_tune_rate=[1.0, 1.0, 1.0, 1.0], folder_name=TRAIN_FOLDER)\n",
    "#     lr = max(lr * 0.4, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step_classifier(self, test_char, test_labels, batch_size, bptt, splits, folder_name='class_test'):\n",
    "    import time\n",
    "    import os\n",
    "    start_time = time.time()\n",
    "    save_path = os.path.join(self.checkpoint_dir, folder_name, 'model.cpkt')\n",
    "    self.test_saver.save(self.session, save_path, global_step=self.session.run(self.global_step))\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    count = 0\n",
    "    predicts = []\n",
    "    y_true = []\n",
    "    for char_inputs, seq_lens, char_lens, true_labels in get_batch_classifier(test_char, test_labels, batch_size, splits, is_training=False):\n",
    "        fd = {\n",
    "            self.model_test.inputs: char_inputs, self.model_test.seq_lens: seq_lens,\n",
    "            self.model_test.char_lens: char_lens, self.model_test.bptt: bptt,\n",
    "            self.true_y: true_labels\n",
    "        }\n",
    "        y_pred, test_loss, test_acc = self.session.run([self.test_classifier.logits, self.test_loss, self.test_acc], feed_dict=fd)\n",
    "        total_loss += test_loss * len(true_labels)\n",
    "        total_acc += test_acc * len(true_labels)\n",
    "        count += len(true_labels)\n",
    "        predicts.append(y_pred)\n",
    "        y_true.append(true_labels)\n",
    "        print(\"Evaluate total loss: {:05.5f}, total acc: {:05.5f}, time {:05.2f}\".format(total_loss/count, total_acc/count, time.time()-start_time))\n",
    "    print(count)\n",
    "    print(total_acc)\n",
    "    return np.argmax(np.concatenate(predicts), axis=-1), np.concatenate(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate total loss: 4.37559, total acc: 0.00000, time 02.05\n",
      "Evaluate total loss: 3.82343, total acc: 0.00000, time 03.20\n",
      "Evaluate total loss: 3.52731, total acc: 0.10000, time 04.76\n",
      "Evaluate total loss: 2.67977, total acc: 0.30000, time 04.94\n",
      "Evaluate total loss: 2.87605, total acc: 0.30000, time 05.06\n",
      "Evaluate total loss: 3.16456, total acc: 0.30000, time 05.30\n",
      "Evaluate total loss: 3.25949, total acc: 0.31429, time 05.42\n",
      "Evaluate total loss: 3.36150, total acc: 0.32500, time 05.53\n",
      "Evaluate total loss: 3.52812, total acc: 0.33333, time 05.64\n",
      "Evaluate total loss: 3.80910, total acc: 0.31000, time 05.81\n",
      "Evaluate total loss: 3.66692, total acc: 0.34545, time 06.06\n",
      "Evaluate total loss: 3.77601, total acc: 0.31667, time 06.19\n",
      "Evaluate total loss: 4.07392, total acc: 0.29231, time 06.31\n",
      "Evaluate total loss: 4.18646, total acc: 0.30000, time 06.54\n",
      "Evaluate total loss: 4.15348, total acc: 0.30667, time 06.72\n",
      "Evaluate total loss: 3.90436, total acc: 0.35000, time 06.79\n",
      "Evaluate total loss: 3.88156, total acc: 0.36471, time 06.85\n",
      "Evaluate total loss: 3.72072, total acc: 0.38333, time 06.92\n",
      "Evaluate total loss: 3.58373, total acc: 0.40526, time 06.98\n",
      "Evaluate total loss: 3.45110, total acc: 0.42500, time 07.06\n",
      "Evaluate total loss: 3.30723, total acc: 0.43810, time 07.10\n",
      "Evaluate total loss: 3.19797, total acc: 0.45000, time 07.15\n",
      "Evaluate total loss: 3.06768, total acc: 0.46957, time 07.22\n",
      "Evaluate total loss: 3.04572, total acc: 0.47500, time 07.27\n",
      "Evaluate total loss: 2.96139, total acc: 0.48800, time 07.33\n",
      "Evaluate total loss: 2.88779, total acc: 0.49615, time 07.38\n",
      "Evaluate total loss: 2.80632, total acc: 0.50741, time 07.45\n",
      "Evaluate total loss: 2.70872, total acc: 0.52500, time 07.51\n",
      "Evaluate total loss: 2.62960, total acc: 0.53793, time 07.56\n",
      "Evaluate total loss: 2.58305, total acc: 0.53667, time 07.59\n",
      "Evaluate total loss: 2.55426, total acc: 0.53548, time 07.63\n",
      "Evaluate total loss: 2.49552, total acc: 0.54375, time 07.67\n",
      "Evaluate total loss: 2.43023, total acc: 0.55455, time 07.72\n",
      "Evaluate total loss: 2.44013, total acc: 0.55588, time 07.78\n",
      "Evaluate total loss: 2.42356, total acc: 0.55714, time 07.85\n",
      "Evaluate total loss: 2.45375, total acc: 0.55278, time 07.90\n",
      "Evaluate total loss: 2.44901, total acc: 0.55405, time 07.96\n",
      "Evaluate total loss: 2.41500, total acc: 0.55789, time 08.00\n",
      "Evaluate total loss: 2.38080, total acc: 0.56667, time 08.04\n",
      "Evaluate total loss: 2.34793, total acc: 0.57000, time 08.08\n",
      "Evaluate total loss: 2.31841, total acc: 0.57317, time 08.12\n",
      "Evaluate total loss: 2.26904, total acc: 0.58095, time 08.17\n",
      "Evaluate total loss: 2.25716, total acc: 0.58140, time 08.21\n",
      "Evaluate total loss: 2.23991, total acc: 0.58409, time 08.26\n",
      "Evaluate total loss: 2.20928, total acc: 0.59111, time 08.32\n",
      "Evaluate total loss: 2.18777, total acc: 0.59130, time 08.37\n",
      "Evaluate total loss: 2.18758, total acc: 0.59149, time 08.44\n",
      "Evaluate total loss: 2.15090, total acc: 0.59583, time 08.50\n",
      "Evaluate total loss: 2.11015, total acc: 0.60204, time 08.56\n",
      "Evaluate total loss: 2.08212, total acc: 0.60600, time 08.61\n",
      "Evaluate total loss: 2.04766, total acc: 0.61176, time 08.65\n",
      "Evaluate total loss: 2.02112, total acc: 0.61731, time 08.70\n",
      "Evaluate total loss: 1.99604, total acc: 0.61887, time 08.74\n",
      "Evaluate total loss: 1.98280, total acc: 0.62222, time 08.78\n",
      "Evaluate total loss: 1.95896, total acc: 0.62364, time 08.82\n",
      "Evaluate total loss: 1.94338, total acc: 0.62500, time 08.89\n",
      "Evaluate total loss: 1.92494, total acc: 0.62281, time 08.94\n",
      "Evaluate total loss: 1.90782, total acc: 0.62586, time 08.99\n",
      "Evaluate total loss: 1.88612, total acc: 0.62881, time 09.05\n",
      "Evaluate total loss: 1.87585, total acc: 0.62833, time 09.09\n",
      "Evaluate total loss: 1.85267, total acc: 0.63115, time 09.14\n",
      "Evaluate total loss: 1.83131, total acc: 0.63226, time 09.18\n",
      "Evaluate total loss: 1.81961, total acc: 0.63492, time 09.23\n",
      "Evaluate total loss: 1.79512, total acc: 0.63750, time 09.28\n",
      "Evaluate total loss: 1.76760, total acc: 0.64308, time 09.32\n",
      "Evaluate total loss: 1.74236, total acc: 0.64848, time 09.39\n",
      "Evaluate total loss: 1.76240, total acc: 0.64478, time 09.45\n",
      "Evaluate total loss: 1.74029, total acc: 0.64853, time 09.50\n",
      "Evaluate total loss: 1.71587, total acc: 0.65362, time 09.54\n",
      "Evaluate total loss: 1.69186, total acc: 0.65857, time 09.59\n",
      "Evaluate total loss: 1.71029, total acc: 0.65775, time 09.63\n",
      "Evaluate total loss: 1.69765, total acc: 0.65833, time 09.70\n",
      "Evaluate total loss: 1.69842, total acc: 0.65890, time 09.74\n",
      "Evaluate total loss: 1.68418, total acc: 0.66081, time 09.79\n",
      "Evaluate total loss: 1.68095, total acc: 0.66133, time 09.86\n",
      "Evaluate total loss: 1.67082, total acc: 0.66316, time 09.93\n",
      "Evaluate total loss: 1.65362, total acc: 0.66623, time 09.98\n",
      "Evaluate total loss: 1.66050, total acc: 0.66538, time 10.03\n",
      "Evaluate total loss: 1.67770, total acc: 0.66203, time 10.07\n",
      "Evaluate total loss: 1.65713, total acc: 0.66625, time 10.14\n",
      "Evaluate total loss: 1.67116, total acc: 0.66420, time 10.19\n",
      "Evaluate total loss: 1.69936, total acc: 0.65976, time 10.24\n",
      "Evaluate total loss: 1.68705, total acc: 0.66024, time 10.28\n",
      "Evaluate total loss: 1.73322, total acc: 0.65476, time 10.35\n",
      "Evaluate total loss: 1.73803, total acc: 0.65529, time 10.40\n",
      "Evaluate total loss: 1.75228, total acc: 0.65233, time 10.48\n",
      "Evaluate total loss: 1.78856, total acc: 0.64713, time 10.55\n",
      "Evaluate total loss: 1.78375, total acc: 0.64773, time 10.62\n",
      "Evaluate total loss: 1.79041, total acc: 0.64944, time 10.67\n",
      "Evaluate total loss: 1.79897, total acc: 0.65000, time 10.70\n",
      "Evaluate total loss: 1.82906, total acc: 0.64615, time 10.76\n",
      "Evaluate total loss: 1.83311, total acc: 0.64348, time 10.80\n",
      "Evaluate total loss: 1.85364, total acc: 0.64301, time 10.87\n",
      "Evaluate total loss: 1.84233, total acc: 0.64362, time 10.94\n",
      "Evaluate total loss: 1.85242, total acc: 0.64105, time 10.98\n",
      "Evaluate total loss: 1.87631, total acc: 0.64063, time 11.02\n",
      "Evaluate total loss: 1.88191, total acc: 0.64124, time 11.06\n",
      "Evaluate total loss: 1.89519, total acc: 0.63980, time 11.11\n",
      "Evaluate total loss: 1.90397, total acc: 0.63939, time 11.15\n",
      "Evaluate total loss: 1.90826, total acc: 0.63800, time 11.19\n",
      "Evaluate total loss: 1.89544, total acc: 0.63960, time 11.27\n",
      "Evaluate total loss: 1.88855, total acc: 0.64020, time 11.33\n",
      "Evaluate total loss: 1.88327, total acc: 0.63883, time 11.42\n",
      "Evaluate total loss: 1.88156, total acc: 0.63750, time 11.46\n",
      "Evaluate total loss: 1.88375, total acc: 0.63810, time 11.51\n",
      "Evaluate total loss: 1.86829, total acc: 0.64057, time 11.55\n",
      "Evaluate total loss: 1.85135, total acc: 0.64393, time 11.59\n",
      "Evaluate total loss: 1.84438, total acc: 0.64352, time 11.65\n",
      "Evaluate total loss: 1.84806, total acc: 0.64220, time 11.71\n",
      "Evaluate total loss: 1.87040, total acc: 0.64091, time 11.77\n",
      "Evaluate total loss: 1.85510, total acc: 0.64414, time 11.79\n",
      "Evaluate total loss: 1.87602, total acc: 0.64196, time 11.84\n",
      "Evaluate total loss: 1.86894, total acc: 0.64248, time 11.90\n",
      "Evaluate total loss: 1.88099, total acc: 0.64123, time 11.97\n",
      "Evaluate total loss: 1.87319, total acc: 0.64261, time 12.02\n",
      "Evaluate total loss: 1.89635, total acc: 0.64138, time 12.06\n",
      "Evaluate total loss: 1.88346, total acc: 0.64274, time 12.11\n",
      "Evaluate total loss: 1.87813, total acc: 0.64407, time 12.17\n",
      "Evaluate total loss: 1.86887, total acc: 0.64538, time 12.25\n",
      "Evaluate total loss: 1.89474, total acc: 0.64250, time 12.31\n",
      "Evaluate total loss: 1.90271, total acc: 0.64215, time 12.36\n",
      "Evaluate total loss: 1.89599, total acc: 0.64344, time 12.41\n",
      "Evaluate total loss: 1.88096, total acc: 0.64634, time 12.45\n",
      "Evaluate total loss: 1.86855, total acc: 0.64839, time 12.50\n",
      "Evaluate total loss: 1.85580, total acc: 0.65040, time 12.52\n",
      "Evaluate total loss: 1.84305, total acc: 0.65238, time 12.54\n",
      "Evaluate total loss: 1.83510, total acc: 0.65433, time 12.57\n",
      "Evaluate total loss: 1.82097, total acc: 0.65703, time 12.63\n",
      "Evaluate total loss: 1.81750, total acc: 0.65736, time 12.68\n",
      "Evaluate total loss: 1.82284, total acc: 0.65615, time 12.73\n",
      "Evaluate total loss: 1.81109, total acc: 0.65725, time 12.77\n",
      "Evaluate total loss: 1.81103, total acc: 0.65682, time 12.80\n",
      "Evaluate total loss: 1.81023, total acc: 0.65564, time 12.87\n",
      "Evaluate total loss: 1.80481, total acc: 0.65597, time 12.92\n",
      "Evaluate total loss: 1.81355, total acc: 0.65556, time 12.97\n",
      "Evaluate total loss: 1.81016, total acc: 0.65515, time 13.04\n",
      "Evaluate total loss: 1.80193, total acc: 0.65547, time 13.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate total loss: 1.79439, total acc: 0.65652, time 13.18\n",
      "Evaluate total loss: 1.79177, total acc: 0.65683, time 13.22\n",
      "Evaluate total loss: 1.79104, total acc: 0.65643, time 13.28\n",
      "Evaluate total loss: 1.79054, total acc: 0.65745, time 13.32\n",
      "Evaluate total loss: 1.78080, total acc: 0.65845, time 13.36\n",
      "Evaluate total loss: 1.78337, total acc: 0.65734, time 13.43\n",
      "Evaluate total loss: 1.78791, total acc: 0.65694, time 13.49\n",
      "Evaluate total loss: 1.78681, total acc: 0.65724, time 13.53\n",
      "Evaluate total loss: 1.78315, total acc: 0.65685, time 13.57\n",
      "Evaluate total loss: 1.77428, total acc: 0.65782, time 13.62\n",
      "Evaluate total loss: 1.76767, total acc: 0.65878, time 13.67\n",
      "Evaluate total loss: 1.77255, total acc: 0.65772, time 13.73\n",
      "Evaluate total loss: 1.77210, total acc: 0.65933, time 13.79\n",
      "Evaluate total loss: 1.77511, total acc: 0.65828, time 13.86\n",
      "Evaluate total loss: 1.76497, total acc: 0.65987, time 13.94\n",
      "Evaluate total loss: 1.76302, total acc: 0.66013, time 13.97\n",
      "Evaluate total loss: 1.76374, total acc: 0.66039, time 14.01\n",
      "Evaluate total loss: 1.76470, total acc: 0.65935, time 14.06\n",
      "Evaluate total loss: 1.76157, total acc: 0.65769, time 14.14\n",
      "Evaluate total loss: 1.75729, total acc: 0.65924, time 14.18\n",
      "Evaluate total loss: 1.75073, total acc: 0.66076, time 14.22\n",
      "Evaluate total loss: 1.74137, total acc: 0.66164, time 14.26\n",
      "Evaluate total loss: 1.74414, total acc: 0.66125, time 14.30\n",
      "Evaluate total loss: 1.75047, total acc: 0.66087, time 14.36\n",
      "Evaluate total loss: 1.74872, total acc: 0.65988, time 14.41\n",
      "Evaluate total loss: 1.75478, total acc: 0.66074, time 14.46\n",
      "Evaluate total loss: 1.74493, total acc: 0.66220, time 14.50\n",
      "Evaluate total loss: 1.75120, total acc: 0.66182, time 14.55\n",
      "Evaluate total loss: 1.74166, total acc: 0.66325, time 14.58\n",
      "Evaluate total loss: 1.74370, total acc: 0.66347, time 14.63\n",
      "Evaluate total loss: 1.74231, total acc: 0.66250, time 14.70\n",
      "Evaluate total loss: 1.73875, total acc: 0.66331, time 14.76\n",
      "Evaluate total loss: 1.74179, total acc: 0.66412, time 14.82\n",
      "Evaluate total loss: 1.74391, total acc: 0.66374, time 14.86\n",
      "Evaluate total loss: 1.74167, total acc: 0.66337, time 14.92\n",
      "Evaluate total loss: 1.74401, total acc: 0.66358, time 14.95\n",
      "Evaluate total loss: 1.75505, total acc: 0.66264, time 15.00\n",
      "Evaluate total loss: 1.75004, total acc: 0.66400, time 15.04\n",
      "Evaluate total loss: 1.75198, total acc: 0.66420, time 15.11\n",
      "Evaluate total loss: 1.75564, total acc: 0.66441, time 15.14\n",
      "Evaluate total loss: 1.74895, total acc: 0.66517, time 15.18\n",
      "Evaluate total loss: 1.75952, total acc: 0.66480, time 15.22\n",
      "Evaluate total loss: 1.76038, total acc: 0.66556, time 15.27\n",
      "Evaluate total loss: 1.75888, total acc: 0.66575, time 15.32\n",
      "Evaluate total loss: 1.74925, total acc: 0.66758, time 15.36\n",
      "Evaluate total loss: 1.75110, total acc: 0.66831, time 15.42\n",
      "Evaluate total loss: 1.75501, total acc: 0.66848, time 15.48\n",
      "Evaluate total loss: 1.74644, total acc: 0.66973, time 15.52\n",
      "Evaluate total loss: 1.75356, total acc: 0.66882, time 15.57\n",
      "Evaluate total loss: 1.76301, total acc: 0.66845, time 15.61\n",
      "Evaluate total loss: 1.75994, total acc: 0.66809, time 15.66\n",
      "Evaluate total loss: 1.75993, total acc: 0.66825, time 15.71\n",
      "Evaluate total loss: 1.76264, total acc: 0.66789, time 15.77\n",
      "Evaluate total loss: 1.75650, total acc: 0.66859, time 15.80\n",
      "Evaluate total loss: 1.75360, total acc: 0.66927, time 15.85\n",
      "Evaluate total loss: 1.76123, total acc: 0.66736, time 15.89\n",
      "Evaluate total loss: 1.75255, total acc: 0.66907, time 15.92\n",
      "Evaluate total loss: 1.76229, total acc: 0.66821, time 15.98\n",
      "Evaluate total loss: 1.77364, total acc: 0.66786, time 16.01\n",
      "Evaluate total loss: 1.76899, total acc: 0.66802, time 16.08\n",
      "Evaluate total loss: 1.76193, total acc: 0.66869, time 16.13\n",
      "Evaluate total loss: 1.76438, total acc: 0.66935, time 16.17\n",
      "Evaluate total loss: 1.76166, total acc: 0.66800, time 16.20\n",
      "Evaluate total loss: 1.76008, total acc: 0.66866, time 16.24\n",
      "Evaluate total loss: 1.75701, total acc: 0.66931, time 16.27\n",
      "Evaluate total loss: 1.74895, total acc: 0.67044, time 16.29\n",
      "Evaluate total loss: 1.75002, total acc: 0.67059, time 16.33\n",
      "Evaluate total loss: 1.74343, total acc: 0.67122, time 16.39\n",
      "Evaluate total loss: 1.74065, total acc: 0.67233, time 16.43\n",
      "Evaluate total loss: 1.74016, total acc: 0.67246, time 16.48\n",
      "Evaluate total loss: 1.73656, total acc: 0.67308, time 16.53\n",
      "Evaluate total loss: 1.72845, total acc: 0.67464, time 16.57\n",
      "Evaluate total loss: 1.72082, total acc: 0.67571, time 16.60\n",
      "Evaluate total loss: 1.71854, total acc: 0.67678, time 16.63\n",
      "Evaluate total loss: 1.72128, total acc: 0.67689, time 16.68\n",
      "Evaluate total loss: 1.71632, total acc: 0.67746, time 16.71\n",
      "Evaluate total loss: 1.71116, total acc: 0.67850, time 16.74\n",
      "Evaluate total loss: 1.71382, total acc: 0.67767, time 16.77\n",
      "Evaluate total loss: 1.70694, total acc: 0.67824, time 16.81\n",
      "Evaluate total loss: 1.71218, total acc: 0.67696, time 16.87\n",
      "Evaluate total loss: 1.71058, total acc: 0.67752, time 16.90\n",
      "Evaluate total loss: 1.70730, total acc: 0.67763, time 16.95\n",
      "Evaluate total loss: 1.70903, total acc: 0.67727, time 16.99\n",
      "Evaluate total loss: 1.70975, total acc: 0.67783, time 17.02\n",
      "Evaluate total loss: 1.71149, total acc: 0.67793, time 17.07\n",
      "Evaluate total loss: 1.72444, total acc: 0.67713, time 17.12\n",
      "Evaluate total loss: 1.72013, total acc: 0.67768, time 17.18\n",
      "Evaluate total loss: 1.72931, total acc: 0.67644, time 17.21\n",
      "Evaluate total loss: 1.73431, total acc: 0.67655, time 17.26\n",
      "Evaluate total loss: 1.73367, total acc: 0.67621, time 17.30\n",
      "Evaluate total loss: 1.74254, total acc: 0.67500, time 17.37\n",
      "Evaluate total loss: 1.74066, total acc: 0.67511, time 17.42\n",
      "Evaluate total loss: 1.74043, total acc: 0.67522, time 17.49\n",
      "Evaluate total loss: 1.74353, total acc: 0.67489, time 17.53\n",
      "Evaluate total loss: 1.74153, total acc: 0.67457, time 17.58\n",
      "Evaluate total loss: 1.74256, total acc: 0.67425, time 17.62\n",
      "Evaluate total loss: 1.74115, total acc: 0.67479, time 17.67\n",
      "Evaluate total loss: 1.73702, total acc: 0.67574, time 17.70\n",
      "Evaluate total loss: 1.74018, total acc: 0.67500, time 17.74\n",
      "Evaluate total loss: 1.73890, total acc: 0.67511, time 17.80\n",
      "Evaluate total loss: 1.75384, total acc: 0.67353, time 17.85\n",
      "Evaluate total loss: 1.75125, total acc: 0.67364, time 17.90\n",
      "Evaluate total loss: 1.75294, total acc: 0.67375, time 17.95\n",
      "Evaluate total loss: 1.76660, total acc: 0.67261, time 18.00\n",
      "Evaluate total loss: 1.76655, total acc: 0.67231, time 18.04\n",
      "Evaluate total loss: 1.76747, total acc: 0.67160, time 18.11\n",
      "Evaluate total loss: 1.77336, total acc: 0.67131, time 18.17\n",
      "Evaluate total loss: 1.76822, total acc: 0.67184, time 18.25\n",
      "Evaluate total loss: 1.76290, total acc: 0.67236, time 18.29\n",
      "Evaluate total loss: 1.76327, total acc: 0.67247, time 18.32\n",
      "Evaluate total loss: 1.76863, total acc: 0.67218, time 18.34\n",
      "Evaluate total loss: 1.76530, total acc: 0.67229, time 18.39\n",
      "Evaluate total loss: 1.78200, total acc: 0.67040, time 18.44\n",
      "Evaluate total loss: 1.78326, total acc: 0.67012, time 18.48\n",
      "Evaluate total loss: 1.79440, total acc: 0.66825, time 18.53\n",
      "Evaluate total loss: 1.79006, total acc: 0.66877, time 18.57\n",
      "Evaluate total loss: 1.79613, total acc: 0.66811, time 18.62\n",
      "Evaluate total loss: 1.80453, total acc: 0.66706, time 18.68\n",
      "Evaluate total loss: 1.81284, total acc: 0.66563, time 18.73\n",
      "Evaluate total loss: 1.81011, total acc: 0.66537, time 18.79\n",
      "Evaluate total loss: 1.81823, total acc: 0.66434, time 18.83\n",
      "Evaluate total loss: 1.82139, total acc: 0.66332, time 18.88\n",
      "Evaluate total loss: 1.82119, total acc: 0.66308, time 18.93\n",
      "Evaluate total loss: 1.82202, total acc: 0.66169, time 18.97\n",
      "Evaluate total loss: 1.82286, total acc: 0.66031, time 19.01\n",
      "Evaluate total loss: 1.83512, total acc: 0.65856, time 19.05\n",
      "Evaluate total loss: 1.83335, total acc: 0.65909, time 19.09\n",
      "Evaluate total loss: 1.85282, total acc: 0.65736, time 19.13\n",
      "Evaluate total loss: 1.85465, total acc: 0.65714, time 19.20\n",
      "Evaluate total loss: 1.84974, total acc: 0.65730, time 19.24\n",
      "Evaluate total loss: 1.84409, total acc: 0.65821, time 19.28\n",
      "Evaluate total loss: 1.83938, total acc: 0.65911, time 19.32\n",
      "Evaluate total loss: 1.83394, total acc: 0.66000, time 19.36\n",
      "Evaluate total loss: 1.83251, total acc: 0.66015, time 19.40\n",
      "Evaluate total loss: 1.82918, total acc: 0.65993, time 19.47\n",
      "Evaluate total loss: 1.83103, total acc: 0.65934, time 19.52\n",
      "Evaluate total loss: 1.82815, total acc: 0.65949, time 19.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate total loss: 1.82285, total acc: 0.66036, time 19.61\n",
      "Evaluate total loss: 1.81932, total acc: 0.66014, time 19.65\n",
      "Evaluate total loss: 1.81333, total acc: 0.66101, time 19.69\n",
      "Evaluate total loss: 1.81241, total acc: 0.66043, time 19.76\n",
      "Evaluate total loss: 1.80629, total acc: 0.66165, time 19.81\n",
      "Evaluate total loss: 1.79998, total acc: 0.66286, time 19.85\n",
      "Evaluate total loss: 1.79944, total acc: 0.66299, time 19.90\n",
      "Evaluate total loss: 1.79647, total acc: 0.66348, time 19.95\n",
      "Evaluate total loss: 1.80137, total acc: 0.66219, time 20.00\n",
      "Evaluate total loss: 1.80605, total acc: 0.66127, time 20.04\n",
      "Evaluate total loss: 1.81581, total acc: 0.66000, time 20.09\n",
      "Evaluate total loss: 1.82406, total acc: 0.65909, time 20.13\n",
      "Evaluate total loss: 1.83202, total acc: 0.65819, time 20.17\n",
      "Evaluate total loss: 1.83161, total acc: 0.65764, time 20.22\n",
      "Evaluate total loss: 1.83522, total acc: 0.65709, time 20.25\n",
      "Evaluate total loss: 1.84038, total acc: 0.65621, time 20.29\n",
      "Evaluate total loss: 1.84840, total acc: 0.65464, time 20.33\n",
      "Evaluate total loss: 1.84875, total acc: 0.65479, time 20.38\n",
      "Evaluate total loss: 1.85738, total acc: 0.65392, time 20.42\n",
      "Evaluate total loss: 1.86537, total acc: 0.65306, time 20.47\n",
      "Evaluate total loss: 1.86482, total acc: 0.65288, time 20.51\n",
      "Evaluate total loss: 1.86960, total acc: 0.65270, time 20.57\n",
      "Evaluate total loss: 1.87550, total acc: 0.65219, time 20.61\n",
      "Evaluate total loss: 1.88457, total acc: 0.65134, time 20.66\n",
      "Evaluate total loss: 1.88624, total acc: 0.65117, time 20.70\n",
      "Evaluate total loss: 1.88628, total acc: 0.65067, time 20.79\n",
      "Evaluate total loss: 1.88597, total acc: 0.65083, time 20.84\n",
      "Evaluate total loss: 1.88657, total acc: 0.65099, time 20.90\n",
      "Evaluate total loss: 1.88036, total acc: 0.65215, time 20.94\n",
      "Evaluate total loss: 1.87597, total acc: 0.65263, time 20.97\n",
      "Evaluate total loss: 1.87359, total acc: 0.65344, time 21.01\n",
      "Evaluate total loss: 1.87091, total acc: 0.65425, time 21.06\n",
      "Evaluate total loss: 1.86666, total acc: 0.65505, time 21.11\n",
      "Evaluate total loss: 1.86296, total acc: 0.65487, time 21.15\n",
      "Evaluate total loss: 1.86102, total acc: 0.65502, time 21.21\n",
      "Evaluate total loss: 1.86210, total acc: 0.65516, time 21.26\n",
      "Evaluate total loss: 1.85690, total acc: 0.65595, time 21.29\n",
      "Evaluate total loss: 1.85682, total acc: 0.65641, time 21.32\n",
      "Evaluate total loss: 1.85101, total acc: 0.65751, time 21.39\n",
      "Evaluate total loss: 1.85544, total acc: 0.65732, time 21.41\n",
      "Evaluate total loss: 1.85215, total acc: 0.65746, time 21.45\n",
      "Evaluate total loss: 1.85687, total acc: 0.65728, time 21.52\n",
      "Evaluate total loss: 1.85539, total acc: 0.65741, time 21.55\n",
      "Evaluate total loss: 1.85424, total acc: 0.65755, time 21.61\n",
      "Evaluate total loss: 1.85131, total acc: 0.65799, time 21.66\n",
      "Evaluate total loss: 1.84968, total acc: 0.65781, time 21.73\n",
      "Evaluate total loss: 1.85384, total acc: 0.65701, time 21.77\n",
      "Evaluate total loss: 1.85915, total acc: 0.65590, time 21.81\n",
      "Evaluate total loss: 1.85769, total acc: 0.65604, time 21.87\n",
      "Evaluate total loss: 1.85720, total acc: 0.65617, time 21.91\n",
      "Evaluate total loss: 1.85562, total acc: 0.65631, time 21.94\n",
      "Evaluate total loss: 1.86091, total acc: 0.65521, time 22.01\n",
      "Evaluate total loss: 1.85927, total acc: 0.65566, time 22.05\n",
      "Evaluate total loss: 1.86180, total acc: 0.65579, time 22.12\n",
      "Evaluate total loss: 1.87581, total acc: 0.65532, time 22.17\n",
      "Evaluate total loss: 1.87598, total acc: 0.65606, time 22.21\n",
      "Evaluate total loss: 1.87389, total acc: 0.65650, time 22.25\n",
      "Evaluate total loss: 1.87268, total acc: 0.65663, time 22.29\n",
      "Evaluate total loss: 1.86878, total acc: 0.65736, time 22.32\n",
      "Evaluate total loss: 1.87626, total acc: 0.65659, time 22.36\n",
      "Evaluate total loss: 1.88102, total acc: 0.65642, time 22.41\n",
      "Evaluate total loss: 1.87703, total acc: 0.65714, time 22.45\n",
      "Evaluate total loss: 1.87322, total acc: 0.65697, time 22.50\n",
      "Evaluate total loss: 1.86836, total acc: 0.65769, time 22.53\n",
      "Evaluate total loss: 1.87104, total acc: 0.65782, time 22.56\n",
      "Evaluate total loss: 1.87115, total acc: 0.65794, time 22.60\n",
      "Evaluate total loss: 1.87559, total acc: 0.65748, time 22.65\n",
      "Evaluate total loss: 1.87130, total acc: 0.65789, time 22.70\n",
      "Evaluate total loss: 1.87777, total acc: 0.65714, time 22.75\n",
      "Evaluate total loss: 1.87615, total acc: 0.65669, time 22.79\n",
      "Evaluate total loss: 1.88023, total acc: 0.65623, time 22.84\n",
      "Evaluate total loss: 1.88708, total acc: 0.65549, time 22.90\n",
      "Evaluate total loss: 1.88886, total acc: 0.65533, time 22.94\n",
      "Evaluate total loss: 1.88750, total acc: 0.65546, time 22.98\n",
      "Evaluate total loss: 1.89131, total acc: 0.65501, time 23.04\n",
      "Evaluate total loss: 1.89453, total acc: 0.65486, time 23.11\n",
      "Evaluate total loss: 1.89494, total acc: 0.65470, time 23.15\n",
      "Evaluate total loss: 1.89350, total acc: 0.65483, time 23.19\n",
      "Evaluate total loss: 1.89304, total acc: 0.65467, time 23.22\n",
      "Evaluate total loss: 1.90949, total acc: 0.65367, time 23.28\n",
      "Evaluate total loss: 1.90939, total acc: 0.65380, time 23.33\n",
      "Evaluate total loss: 1.91121, total acc: 0.65281, time 23.37\n",
      "Evaluate total loss: 1.91788, total acc: 0.65238, time 23.43\n",
      "Evaluate total loss: 1.92203, total acc: 0.65140, time 23.46\n",
      "Evaluate total loss: 1.92509, total acc: 0.65042, time 23.51\n",
      "Evaluate total loss: 1.92438, total acc: 0.65028, time 23.55\n",
      "Evaluate total loss: 1.92274, total acc: 0.65069, time 23.60\n",
      "Evaluate total loss: 1.92752, total acc: 0.64945, time 23.67\n",
      "Evaluate total loss: 1.92688, total acc: 0.64959, time 23.72\n",
      "Evaluate total loss: 1.93321, total acc: 0.64890, time 23.77\n",
      "Evaluate total loss: 1.93567, total acc: 0.64877, time 23.82\n",
      "Evaluate total loss: 1.94297, total acc: 0.64809, time 23.86\n",
      "Evaluate total loss: 1.94420, total acc: 0.64796, time 23.89\n",
      "Evaluate total loss: 1.94175, total acc: 0.64783, time 23.93\n",
      "Evaluate total loss: 1.93826, total acc: 0.64797, time 23.97\n",
      "Evaluate total loss: 1.94637, total acc: 0.64649, time 24.01\n",
      "Evaluate total loss: 1.95175, total acc: 0.64501, time 24.06\n",
      "Evaluate total loss: 1.95778, total acc: 0.64355, time 24.10\n",
      "Evaluate total loss: 1.96050, total acc: 0.64343, time 24.14\n",
      "Evaluate total loss: 1.96219, total acc: 0.64305, time 24.18\n",
      "Evaluate total loss: 1.96290, total acc: 0.64240, time 24.23\n",
      "Evaluate total loss: 1.95888, total acc: 0.64309, time 24.26\n",
      "Evaluate total loss: 1.95452, total acc: 0.64324, time 24.32\n",
      "Evaluate total loss: 1.95088, total acc: 0.64392, time 24.36\n",
      "Evaluate total loss: 1.94747, total acc: 0.64433, time 24.39\n",
      "Evaluate total loss: 1.94897, total acc: 0.64447, time 24.44\n",
      "Evaluate total loss: 1.95254, total acc: 0.64436, time 24.49\n",
      "Evaluate total loss: 1.95128, total acc: 0.64424, time 24.52\n",
      "Evaluate total loss: 1.96012, total acc: 0.64308, time 24.58\n",
      "Evaluate total loss: 1.95961, total acc: 0.64297, time 24.62\n",
      "Evaluate total loss: 1.96182, total acc: 0.64260, time 24.68\n",
      "Evaluate total loss: 1.96463, total acc: 0.64223, time 24.74\n",
      "Evaluate total loss: 1.96792, total acc: 0.64186, time 24.80\n",
      "Evaluate total loss: 1.96390, total acc: 0.64253, time 24.85\n",
      "Evaluate total loss: 1.96288, total acc: 0.64293, time 24.89\n",
      "Evaluate total loss: 1.96185, total acc: 0.64308, time 24.95\n",
      "Evaluate total loss: 1.95894, total acc: 0.64373, time 25.00\n",
      "Evaluate total loss: 1.95864, total acc: 0.64362, time 25.05\n",
      "Evaluate total loss: 1.95995, total acc: 0.64326, time 25.10\n",
      "Evaluate total loss: 1.96379, total acc: 0.64264, time 25.14\n",
      "Evaluate total loss: 1.96987, total acc: 0.64177, time 25.19\n",
      "Evaluate total loss: 1.96518, total acc: 0.64268, time 25.23\n",
      "Evaluate total loss: 1.96038, total acc: 0.64358, time 25.26\n",
      "Evaluate total loss: 1.96364, total acc: 0.64347, time 25.31\n",
      "Evaluate total loss: 1.96618, total acc: 0.64286, time 25.36\n",
      "Evaluate total loss: 1.96428, total acc: 0.64300, time 25.41\n",
      "Evaluate total loss: 1.96635, total acc: 0.64239, time 25.46\n",
      "Evaluate total loss: 1.96349, total acc: 0.64303, time 25.49\n",
      "Evaluate total loss: 1.96014, total acc: 0.64342, time 25.55\n",
      "Evaluate total loss: 1.96115, total acc: 0.64332, time 25.59\n",
      "Evaluate total loss: 1.96302, total acc: 0.64346, time 25.64\n",
      "Evaluate total loss: 1.96210, total acc: 0.64384, time 25.68\n",
      "Evaluate total loss: 1.96496, total acc: 0.64349, time 25.75\n",
      "Evaluate total loss: 1.96111, total acc: 0.64412, time 25.78\n",
      "Evaluate total loss: 1.96586, total acc: 0.64352, time 25.84\n",
      "Evaluate total loss: 1.96389, total acc: 0.64341, time 25.89\n",
      "Evaluate total loss: 1.96569, total acc: 0.64331, time 25.94\n",
      "Evaluate total loss: 1.96827, total acc: 0.64272, time 25.98\n",
      "Evaluate total loss: 1.96772, total acc: 0.64286, time 26.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate total loss: 1.96533, total acc: 0.64275, time 26.09\n",
      "Evaluate total loss: 1.96641, total acc: 0.64265, time 26.16\n",
      "Evaluate total loss: 1.96914, total acc: 0.64231, time 26.20\n",
      "Evaluate total loss: 1.97315, total acc: 0.64149, time 26.24\n",
      "Evaluate total loss: 1.97325, total acc: 0.64187, time 26.30\n",
      "Evaluate total loss: 1.97557, total acc: 0.64129, time 26.35\n",
      "Evaluate total loss: 1.97759, total acc: 0.64119, time 26.38\n",
      "Evaluate total loss: 1.98117, total acc: 0.64062, time 26.43\n",
      "Evaluate total loss: 1.98693, total acc: 0.63981, time 26.49\n",
      "Evaluate total loss: 1.99096, total acc: 0.63924, time 26.54\n",
      "Evaluate total loss: 1.99168, total acc: 0.63892, time 26.58\n",
      "Evaluate total loss: 1.99603, total acc: 0.63835, time 26.62\n",
      "Evaluate total loss: 1.99477, total acc: 0.63803, time 26.66\n",
      "Evaluate total loss: 2.00412, total acc: 0.63677, time 26.72\n",
      "Evaluate total loss: 2.00205, total acc: 0.63692, time 26.76\n",
      "Evaluate total loss: 2.01003, total acc: 0.63566, time 26.80\n",
      "Evaluate total loss: 2.00901, total acc: 0.63581, time 26.84\n",
      "Evaluate total loss: 2.01313, total acc: 0.63573, time 26.87\n",
      "Evaluate total loss: 2.02049, total acc: 0.63472, time 26.93\n",
      "Evaluate total loss: 2.02178, total acc: 0.63464, time 26.97\n",
      "Evaluate total loss: 2.02368, total acc: 0.63433, time 27.01\n",
      "Evaluate total loss: 2.02420, total acc: 0.63356, time 27.05\n",
      "Evaluate total loss: 2.02667, total acc: 0.63326, time 27.11\n",
      "Evaluate total loss: 2.02491, total acc: 0.63341, time 27.15\n",
      "Evaluate total loss: 2.02481, total acc: 0.63288, time 27.18\n",
      "Evaluate total loss: 2.02610, total acc: 0.63257, time 27.25\n",
      "Evaluate total loss: 2.03451, total acc: 0.63182, time 27.30\n",
      "Evaluate total loss: 2.03469, total acc: 0.63197, time 27.35\n",
      "Evaluate total loss: 2.03386, total acc: 0.63213, time 27.40\n",
      "Evaluate total loss: 2.03337, total acc: 0.63205, time 27.45\n",
      "Evaluate total loss: 2.03227, total acc: 0.63198, time 27.49\n",
      "Evaluate total loss: 2.03103, total acc: 0.63213, time 27.54\n",
      "Evaluate total loss: 2.03353, total acc: 0.63206, time 27.62\n",
      "Evaluate total loss: 2.03587, total acc: 0.63199, time 27.68\n",
      "Evaluate total loss: 2.04134, total acc: 0.63147, time 27.76\n",
      "Evaluate total loss: 2.04699, total acc: 0.63096, time 27.80\n",
      "Evaluate total loss: 2.05401, total acc: 0.62978, time 27.85\n",
      "Evaluate total loss: 2.05415, total acc: 0.63016, time 27.89\n",
      "Evaluate total loss: 2.05537, total acc: 0.62965, time 27.92\n",
      "Evaluate total loss: 2.05799, total acc: 0.62958, time 27.95\n",
      "Evaluate total loss: 2.05574, total acc: 0.62952, time 27.99\n",
      "Evaluate total loss: 2.06288, total acc: 0.62835, time 28.03\n",
      "Evaluate total loss: 2.06899, total acc: 0.62763, time 28.07\n",
      "Evaluate total loss: 2.06686, total acc: 0.62801, time 28.11\n",
      "Evaluate total loss: 2.06747, total acc: 0.62751, time 28.15\n",
      "Evaluate total loss: 2.06331, total acc: 0.62810, time 28.18\n",
      "Evaluate total loss: 2.05903, total acc: 0.62891, time 28.23\n",
      "Evaluate total loss: 2.05725, total acc: 0.62928, time 28.27\n",
      "Evaluate total loss: 2.05731, total acc: 0.62965, time 28.32\n",
      "Evaluate total loss: 2.05576, total acc: 0.62959, time 28.38\n",
      "Evaluate total loss: 2.06130, total acc: 0.62909, time 28.44\n",
      "Evaluate total loss: 2.06393, total acc: 0.62882, time 28.50\n",
      "Evaluate total loss: 2.06625, total acc: 0.62876, time 28.58\n",
      "Evaluate total loss: 2.06981, total acc: 0.62848, time 28.63\n",
      "Evaluate total loss: 2.07202, total acc: 0.62778, time 28.68\n",
      "Evaluate total loss: 2.07393, total acc: 0.62729, time 28.73\n",
      "Evaluate total loss: 2.07446, total acc: 0.62702, time 28.77\n",
      "Evaluate total loss: 2.07525, total acc: 0.62718, time 28.82\n",
      "Evaluate total loss: 2.07824, total acc: 0.62691, time 28.87\n",
      "Evaluate total loss: 2.07766, total acc: 0.62706, time 28.90\n",
      "Evaluate total loss: 2.07656, total acc: 0.62722, time 28.95\n",
      "Evaluate total loss: 2.07791, total acc: 0.62695, time 29.00\n",
      "Evaluate total loss: 2.08038, total acc: 0.62689, time 29.05\n",
      "Evaluate total loss: 2.08380, total acc: 0.62683, time 29.09\n",
      "Evaluate total loss: 2.08267, total acc: 0.62678, time 29.13\n",
      "Evaluate total loss: 2.08572, total acc: 0.62589, time 29.17\n",
      "Evaluate total loss: 2.08762, total acc: 0.62542, time 29.21\n",
      "Evaluate total loss: 2.08794, total acc: 0.62536, time 29.27\n",
      "Evaluate total loss: 2.09132, total acc: 0.62510, time 29.33\n",
      "Evaluate total loss: 2.09142, total acc: 0.62484, time 29.37\n",
      "Evaluate total loss: 2.09150, total acc: 0.62459, time 29.42\n",
      "Evaluate total loss: 2.09421, total acc: 0.62433, time 29.45\n",
      "Evaluate total loss: 2.09551, total acc: 0.62387, time 29.49\n",
      "Evaluate total loss: 2.09458, total acc: 0.62382, time 29.54\n",
      "Evaluate total loss: 2.09183, total acc: 0.62398, time 29.58\n",
      "Evaluate total loss: 2.09023, total acc: 0.62413, time 29.61\n",
      "Evaluate total loss: 2.09123, total acc: 0.62367, time 29.66\n",
      "Evaluate total loss: 2.09377, total acc: 0.62342, time 29.71\n",
      "Evaluate total loss: 2.09958, total acc: 0.62297, time 29.75\n",
      "Evaluate total loss: 2.10334, total acc: 0.62231, time 29.79\n",
      "Evaluate total loss: 2.10949, total acc: 0.62166, time 29.86\n",
      "Evaluate total loss: 2.10772, total acc: 0.62141, time 29.93\n",
      "Evaluate total loss: 2.10574, total acc: 0.62157, time 29.96\n",
      "Evaluate total loss: 2.10210, total acc: 0.62193, time 29.99\n",
      "Evaluate total loss: 2.09839, total acc: 0.62249, time 30.05\n",
      "Evaluate total loss: 2.09979, total acc: 0.62244, time 30.09\n",
      "Evaluate total loss: 2.09659, total acc: 0.62300, time 30.11\n",
      "Evaluate total loss: 2.09863, total acc: 0.62275, time 30.16\n",
      "Evaluate total loss: 2.10285, total acc: 0.62271, time 30.21\n",
      "Evaluate total loss: 2.09880, total acc: 0.62346, time 30.23\n",
      "Evaluate total loss: 2.09468, total acc: 0.62421, time 30.26\n",
      "Evaluate total loss: 2.09163, total acc: 0.62455, time 30.30\n",
      "Evaluate total loss: 2.08988, total acc: 0.62470, time 30.37\n",
      "Evaluate total loss: 2.08649, total acc: 0.62505, time 30.41\n",
      "Evaluate total loss: 2.08342, total acc: 0.62539, time 30.45\n",
      "Evaluate total loss: 2.08360, total acc: 0.62534, time 30.51\n",
      "Evaluate total loss: 2.08133, total acc: 0.62569, time 30.57\n",
      "Evaluate total loss: 2.07774, total acc: 0.62622, time 30.59\n",
      "Evaluate total loss: 2.07452, total acc: 0.62656, time 30.63\n",
      "Evaluate total loss: 2.07242, total acc: 0.62710, time 30.67\n",
      "Evaluate total loss: 2.07165, total acc: 0.62743, time 30.70\n",
      "Evaluate total loss: 2.07247, total acc: 0.62757, time 30.73\n",
      "Evaluate total loss: 2.06942, total acc: 0.62810, time 30.77\n",
      "Evaluate total loss: 2.06593, total acc: 0.62863, time 30.83\n",
      "Evaluate total loss: 2.06364, total acc: 0.62896, time 30.88\n",
      "Evaluate total loss: 2.06001, total acc: 0.62948, time 30.95\n",
      "Evaluate total loss: 2.05698, total acc: 0.62981, time 30.97\n",
      "Evaluate total loss: 2.05342, total acc: 0.63033, time 30.99\n",
      "Evaluate total loss: 2.05238, total acc: 0.63084, time 31.02\n",
      "Evaluate total loss: 2.04929, total acc: 0.63117, time 31.04\n",
      "Evaluate total loss: 2.04851, total acc: 0.63130, time 31.09\n",
      "Evaluate total loss: 2.04919, total acc: 0.63143, time 31.11\n",
      "Evaluate total loss: 2.04955, total acc: 0.63137, time 31.14\n",
      "Evaluate total loss: 2.04895, total acc: 0.63169, time 31.20\n",
      "Evaluate total loss: 2.04694, total acc: 0.63220, time 31.24\n",
      "Evaluate total loss: 2.04485, total acc: 0.63214, time 31.26\n",
      "Evaluate total loss: 2.04165, total acc: 0.63226, time 31.29\n",
      "Evaluate total loss: 2.03962, total acc: 0.63258, time 31.36\n",
      "Evaluate total loss: 2.03848, total acc: 0.63271, time 31.39\n",
      "Evaluate total loss: 2.03695, total acc: 0.63283, time 31.43\n",
      "Evaluate total loss: 2.03945, total acc: 0.63296, time 31.50\n",
      "Evaluate total loss: 2.03757, total acc: 0.63308, time 31.56\n",
      "Evaluate total loss: 2.03379, total acc: 0.63377, time 31.60\n",
      "Evaluate total loss: 2.03510, total acc: 0.63333, time 31.65\n",
      "Evaluate total loss: 2.03508, total acc: 0.63309, time 31.72\n",
      "Evaluate total loss: 2.03571, total acc: 0.63284, time 31.79\n",
      "Evaluate total loss: 2.03733, total acc: 0.63241, time 31.87\n",
      "Evaluate total loss: 2.04071, total acc: 0.63142, time 31.94\n",
      "Evaluate total loss: 2.04799, total acc: 0.63044, time 32.01\n",
      "Evaluate total loss: 2.05318, total acc: 0.62983, time 32.08\n",
      "Evaluate total loss: 2.05302, total acc: 0.62960, time 32.13\n",
      "Evaluate total loss: 2.04954, total acc: 0.63009, time 32.21\n",
      "Evaluate total loss: 2.04942, total acc: 0.63040, time 32.27\n",
      "Evaluate total loss: 2.04874, total acc: 0.63053, time 32.32\n",
      "Evaluate total loss: 2.04797, total acc: 0.63084, time 32.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate total loss: 2.04986, total acc: 0.63060, time 32.44\n",
      "Evaluate total loss: 2.05338, total acc: 0.63000, time 32.50\n",
      "Evaluate total loss: 2.05366, total acc: 0.62995, time 32.56\n",
      "Evaluate total loss: 2.05528, total acc: 0.62971, time 32.61\n",
      "Evaluate total loss: 2.05553, total acc: 0.62984, time 32.68\n",
      "Evaluate total loss: 2.05218, total acc: 0.63032, time 32.71\n",
      "Evaluate total loss: 2.04950, total acc: 0.63063, time 32.76\n",
      "Evaluate total loss: 2.05273, total acc: 0.63004, time 32.83\n",
      "Evaluate total loss: 2.05023, total acc: 0.63016, time 32.87\n",
      "Evaluate total loss: 2.05188, total acc: 0.62993, time 32.93\n",
      "Evaluate total loss: 2.05142, total acc: 0.62987, time 32.98\n",
      "Evaluate total loss: 2.05416, total acc: 0.62946, time 33.05\n",
      "Evaluate total loss: 2.05487, total acc: 0.62888, time 33.12\n",
      "Evaluate total loss: 2.06232, total acc: 0.62794, time 33.19\n",
      "Evaluate total loss: 2.06307, total acc: 0.62771, time 33.25\n",
      "Evaluate total loss: 2.06204, total acc: 0.62784, time 33.31\n",
      "Evaluate total loss: 2.06601, total acc: 0.62743, time 33.37\n",
      "Evaluate total loss: 2.06413, total acc: 0.62774, time 33.43\n",
      "Evaluate total loss: 2.06052, total acc: 0.62840, time 33.48\n",
      "Evaluate total loss: 2.06339, total acc: 0.62870, time 33.51\n",
      "Evaluate total loss: 2.06175, total acc: 0.62882, time 33.57\n",
      "Evaluate total loss: 2.06664, total acc: 0.62842, time 33.63\n",
      "Evaluate total loss: 2.06512, total acc: 0.62890, time 33.68\n",
      "Evaluate total loss: 2.06437, total acc: 0.62920, time 33.70\n",
      "Evaluate total loss: 2.06482, total acc: 0.62897, time 33.75\n",
      "Evaluate total loss: 2.06256, total acc: 0.62909, time 33.77\n",
      "Evaluate total loss: 2.06087, total acc: 0.62922, time 33.82\n",
      "Evaluate total loss: 2.05816, total acc: 0.62951, time 33.86\n",
      "Evaluate total loss: 2.05709, total acc: 0.62946, time 33.93\n",
      "Evaluate total loss: 2.05363, total acc: 0.63010, time 33.97\n",
      "Evaluate total loss: 2.05104, total acc: 0.63040, time 34.01\n",
      "Evaluate total loss: 2.04920, total acc: 0.63069, time 34.04\n",
      "Evaluate total loss: 2.04853, total acc: 0.63081, time 34.09\n",
      "Evaluate total loss: 2.04586, total acc: 0.63110, time 34.14\n",
      "Evaluate total loss: 2.05119, total acc: 0.63019, time 34.20\n",
      "Evaluate total loss: 2.04894, total acc: 0.63065, time 34.24\n",
      "Evaluate total loss: 2.04866, total acc: 0.63026, time 34.27\n",
      "Evaluate total loss: 2.04993, total acc: 0.62986, time 34.33\n",
      "Evaluate total loss: 2.04875, total acc: 0.62998, time 34.40\n",
      "Evaluate total loss: 2.04727, total acc: 0.63027, time 34.47\n",
      "Evaluate total loss: 2.04557, total acc: 0.63022, time 34.50\n",
      "Evaluate total loss: 2.04419, total acc: 0.63051, time 34.52\n",
      "Evaluate total loss: 2.04479, total acc: 0.63046, time 34.56\n",
      "Evaluate total loss: 2.04243, total acc: 0.63074, time 34.59\n",
      "Evaluate total loss: 2.04105, total acc: 0.63069, time 34.63\n",
      "Evaluate total loss: 2.04199, total acc: 0.63064, time 34.67\n",
      "Evaluate total loss: 2.04337, total acc: 0.63059, time 34.73\n",
      "Evaluate total loss: 2.04192, total acc: 0.63070, time 34.77\n",
      "Evaluate total loss: 2.04117, total acc: 0.63065, time 34.81\n",
      "Evaluate total loss: 2.04270, total acc: 0.63060, time 34.86\n",
      "Evaluate total loss: 2.04271, total acc: 0.63050, time 34.87\n",
      "5981\n",
      "3771.0000152885914\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = eval_step_classifier(my_trainer, test_chars, test_labels, 10, 20, [0, 50, 200], TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9502    0.6156    0.7472      5305\n",
      "           1     0.1985    0.7470    0.3137       676\n",
      "\n",
      "   micro avg     0.6305    0.6305    0.6305      5981\n",
      "   macro avg     0.5744    0.6813    0.5304      5981\n",
      "weighted avg     0.8653    0.6305    0.6982      5981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true, y_pred=y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9466    0.6415    0.7647      5305\n",
      "           1     0.2028    0.7160    0.3161       676\n",
      "\n",
      "   micro avg     0.6499    0.6499    0.6499      5981\n",
      "   macro avg     0.5747    0.6787    0.5404      5981\n",
      "weighted avg     0.8625    0.6499    0.7140      5981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true, y_pred=y_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
