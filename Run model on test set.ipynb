{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from model import LanguageModel\n",
    "import json\n",
    "import numpy as np\n",
    "from utils import batchify, get_batch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # pylint: disable=no-member\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baomoi_punc/word2idx.json', 'r') as inp:\n",
    "    word2idx = json.load(inp)\n",
    "with open('baomoi_punc/char2idx.json', 'r') as inp:\n",
    "    char2idx = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "   \"rnn_layers\":[\n",
    "          {\n",
    "             \"units\": 1024,\n",
    "             \"input_size\": 1024,\n",
    "             \"drop_i\": 0.01,\n",
    "             \"wdrop\": 0.05,\n",
    "             \"drop_o\": 0.01\n",
    "          },\n",
    "          {\n",
    "             \"units\": 1024,\n",
    "             \"input_size\": 1024,\n",
    "             \"wdrop\": 0.05,\n",
    "             \"drop_o\": 0.01\n",
    "          },\n",
    "          {\n",
    "             \"units\": 1024,\n",
    "             \"input_size\": 1024,\n",
    "             \"drop_o\": 0.1,\n",
    "             \"wdrop\": 0.05\n",
    "          }\n",
    "       ],\n",
    "       \"vocab_size\": len(word2idx) + 1,\n",
    "       \"drop_e\": 0.0,\n",
    "       \"char_vocab_size\": len(char2idx) + 1,\n",
    "       \"char_cnn_layers\": [\n",
    "            [1, 16],\n",
    "            [2, 16],\n",
    "            [3, 32],\n",
    "            [4, 64],\n",
    "            [5, 128],\n",
    "            [6, 256],\n",
    "            [7, 512]\n",
    "        ],\n",
    "        \"char_vec_size\": 16,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel(**params, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_model()\n",
    "saver = tf.train.Saver([x for x in tf.global_variables() if x not in tf.get_collection('LSTM_SAVED_STATE')])\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from 11/checkpoints/test/model.cpkt-47181\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, '11/checkpoints/test/model.cpkt-47181')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5835622"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('baomoi_punc/test_char.npy', 'rb') as inp:\n",
    "    test_char = np.load(inp)\n",
    "with open('baomoi_punc/test_word.npy', 'rb') as inp:\n",
    "    test_word = np.load(inp)\n",
    "len(test_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word = batchify(test_word, 38).T\n",
    "test_char = batchify(test_char, 38).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_iy = tf.placeholder(dtype=tf.int32, shape=[None, None], name='fw_y')\n",
    "bw_iy = tf.placeholder(dtype=tf.int32, shape=[None, None], name='bw_y')\n",
    "test_loss = 0.5 * tf.add(\n",
    "    tf.contrib.seq2seq.sequence_loss(\n",
    "        logits=model.fw_model['decoder'],\n",
    "        targets=fw_iy,\n",
    "        weights=model.seq_masks,\n",
    "        average_across_timesteps=True,\n",
    "        average_across_batch=True),\n",
    "    tf.contrib.seq2seq.sequence_loss(\n",
    "        logits=model.bw_model['decoder'],\n",
    "        targets=bw_iy,\n",
    "        weights=model.seq_masks,\n",
    "        average_across_timesteps=True,\n",
    "        average_across_batch=True),\n",
    "    name='test_loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_step(test_word, test_char, bptt):\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "    step = None\n",
    "    for i in range(0, len(test_word), bptt):\n",
    "        (fw_x, fw_y), (bw_x, bw_y) = get_batch(test_word, test_char, bptt, i, evaluate=True)\n",
    "        loss = sess.run(\n",
    "            test_loss,\n",
    "            feed_dict={\n",
    "                model.fw_inputs: fw_x,\n",
    "                model.bw_inputs: bw_x,\n",
    "                fw_iy: fw_y,\n",
    "                bw_iy: bw_y,\n",
    "                model.seq_lens: [fw_y.shape[0]] * fw_y.shape[1],\n",
    "                model.reset_state: i == 0\n",
    "            }\n",
    "        )\n",
    "        total_loss += loss * len(fw_y)\n",
    "        print(\"Evaluate loss {}, time {}\".format(loss, time.time()-start_time))\n",
    "    total_loss /= len(test_word)\n",
    "    print(\"Evaluate total loss {}, time {}\".format(total_loss, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 3.69686222076416, time 0.6846129894256592\n",
      "Evaluate loss 3.551373243331909, time 0.9483013153076172\n",
      "Evaluate loss 3.5342602729797363, time 1.2975621223449707\n",
      "Evaluate loss 3.5873868465423584, time 1.5611605644226074\n",
      "Evaluate loss 3.602341890335083, time 1.9999737739562988\n",
      "Evaluate loss 3.626741647720337, time 2.3224804401397705\n",
      "Evaluate loss 3.456254720687866, time 2.67144513130188\n",
      "Evaluate loss 3.3528120517730713, time 2.9059252738952637\n",
      "Evaluate loss 3.467489242553711, time 3.1477320194244385\n",
      "Evaluate loss 3.506603717803955, time 3.499591827392578\n",
      "Evaluate loss 3.5235543251037598, time 3.7362241744995117\n",
      "Evaluate loss 3.436035633087158, time 4.074859380722046\n",
      "Evaluate loss 3.506998062133789, time 4.3129377365112305\n",
      "Evaluate loss 3.560364007949829, time 4.651585817337036\n",
      "Evaluate loss 3.607978582382202, time 4.883833646774292\n",
      "Evaluate loss 3.5692455768585205, time 5.116603374481201\n",
      "Evaluate loss 3.567150831222534, time 5.456765413284302\n",
      "Evaluate loss 3.5863871574401855, time 5.691469430923462\n",
      "Evaluate loss 3.538771629333496, time 6.024484395980835\n",
      "Evaluate loss 3.601992130279541, time 6.257384300231934\n",
      "Evaluate loss 3.6923038959503174, time 6.49094820022583\n",
      "Evaluate loss 3.6909430027008057, time 6.848291635513306\n",
      "Evaluate loss 3.6301987171173096, time 7.083256483078003\n",
      "Evaluate loss 3.635477066040039, time 7.320292949676514\n",
      "Evaluate loss 3.5781824588775635, time 7.663138151168823\n",
      "Evaluate loss 3.5926566123962402, time 7.899516582489014\n",
      "Evaluate loss 3.5883264541625977, time 8.138816833496094\n",
      "Evaluate loss 3.584303379058838, time 8.456998586654663\n",
      "Evaluate loss 3.604673385620117, time 8.726535320281982\n",
      "Evaluate loss 3.559030532836914, time 9.049559593200684\n",
      "Evaluate loss 3.5169525146484375, time 9.2861909866333\n",
      "Evaluate loss 3.4759275913238525, time 9.549405813217163\n",
      "Evaluate loss 3.5106496810913086, time 9.876829624176025\n",
      "Evaluate loss 3.683483839035034, time 10.113287687301636\n",
      "Evaluate loss 3.680499315261841, time 10.452726125717163\n",
      "Evaluate loss 3.6944990158081055, time 10.6875581741333\n",
      "Evaluate loss 3.718576669692993, time 10.922576427459717\n",
      "Evaluate loss 3.6168811321258545, time 11.277249336242676\n",
      "Evaluate loss 3.7640931606292725, time 11.5106520652771\n",
      "Evaluate loss 3.643972635269165, time 11.85115671157837\n",
      "Evaluate loss 3.5334465503692627, time 12.144916772842407\n",
      "Evaluate loss 3.517559051513672, time 12.449945449829102\n",
      "Evaluate loss 3.5584096908569336, time 12.717517137527466\n",
      "Evaluate loss 3.4541635513305664, time 13.118184089660645\n",
      "Evaluate loss 3.4848108291625977, time 13.406711101531982\n",
      "Evaluate loss 3.4593491554260254, time 13.695221662521362\n",
      "Evaluate loss 3.439622640609741, time 13.981508493423462\n",
      "Evaluate loss 3.471021890640259, time 14.216856241226196\n",
      "Evaluate loss 3.4154446125030518, time 14.55692458152771\n",
      "Evaluate loss 3.3275089263916016, time 14.793763399124146\n",
      "Evaluate loss 3.4454450607299805, time 15.028452634811401\n",
      "Evaluate loss 3.451618194580078, time 15.336998224258423\n",
      "Evaluate loss 3.5899932384490967, time 15.64926815032959\n",
      "Evaluate loss 3.508211612701416, time 15.890360355377197\n",
      "Evaluate loss 3.551518201828003, time 16.137003421783447\n",
      "Evaluate loss 3.533936023712158, time 16.383864164352417\n",
      "Evaluate loss 3.517213821411133, time 16.709696769714355\n",
      "Evaluate loss 3.4999399185180664, time 16.9533371925354\n",
      "Evaluate loss 3.5518300533294678, time 17.319542407989502\n",
      "Evaluate loss 3.5457026958465576, time 17.561289310455322\n",
      "Evaluate loss 3.495255470275879, time 17.88733959197998\n",
      "Evaluate loss 3.5761868953704834, time 18.13207197189331\n",
      "Evaluate loss 3.552138090133667, time 18.380215644836426\n",
      "Evaluate loss 3.5548386573791504, time 18.702871799468994\n",
      "Evaluate loss 3.549654006958008, time 18.942373514175415\n",
      "Evaluate loss 3.495614767074585, time 19.284069299697876\n",
      "Evaluate loss 3.6452395915985107, time 19.527060985565186\n",
      "Evaluate loss 3.569345235824585, time 19.892040014266968\n",
      "Evaluate loss 3.5341694355010986, time 20.136950492858887\n",
      "Evaluate loss 3.6568245887756348, time 20.373487949371338\n",
      "Evaluate loss 3.5737216472625732, time 20.742283821105957\n",
      "Evaluate loss 3.5540027618408203, time 20.978600025177002\n",
      "Evaluate loss 3.6042613983154297, time 21.2115740776062\n",
      "Evaluate loss 3.576578140258789, time 21.522181272506714\n",
      "Evaluate loss 3.7160725593566895, time 21.801093101501465\n",
      "Evaluate loss 3.591303825378418, time 22.08742666244507\n",
      "Evaluate loss 3.4886364936828613, time 22.384055137634277\n",
      "Evaluate loss 3.533801794052124, time 22.624232292175293\n",
      "Evaluate loss 3.469132900238037, time 22.94465470314026\n",
      "Evaluate loss 3.6201367378234863, time 23.179096460342407\n",
      "Evaluate loss 3.640066146850586, time 23.5247323513031\n",
      "Evaluate loss 3.6670780181884766, time 23.75644278526306\n",
      "Evaluate loss 3.712862253189087, time 24.03843402862549\n",
      "Evaluate loss 3.6965553760528564, time 24.340736627578735\n",
      "Evaluate loss 3.57130765914917, time 24.58142375946045\n",
      "Evaluate loss 3.6004586219787598, time 24.930795669555664\n",
      "Evaluate loss 3.679227113723755, time 25.181434869766235\n",
      "Evaluate loss 3.6174240112304688, time 25.478728532791138\n",
      "Evaluate loss 3.6483891010284424, time 25.71589684486389\n",
      "Evaluate loss 3.6567447185516357, time 26.06047248840332\n",
      "Evaluate loss 3.714866876602173, time 26.29463028907776\n",
      "Evaluate loss 3.5584301948547363, time 26.6422917842865\n",
      "Evaluate loss 3.5570714473724365, time 26.876707315444946\n",
      "Evaluate loss 3.526076316833496, time 27.210500717163086\n",
      "Evaluate loss 3.521160840988159, time 27.446770429611206\n",
      "Evaluate loss 3.5775504112243652, time 27.766462326049805\n",
      "Evaluate loss 3.613656520843506, time 28.01470112800598\n",
      "Evaluate loss 3.6218149662017822, time 28.34139347076416\n",
      "Evaluate loss 3.612931251525879, time 28.574447870254517\n",
      "Evaluate loss 3.636223316192627, time 28.81468653678894\n",
      "Evaluate loss 3.6624908447265625, time 29.149080753326416\n",
      "Evaluate loss 3.601525068283081, time 29.382778882980347\n",
      "Evaluate loss 3.495516538619995, time 29.688454627990723\n",
      "Evaluate loss 3.5240533351898193, time 29.968727350234985\n",
      "Evaluate loss 3.4265007972717285, time 30.203773021697998\n",
      "Evaluate loss 3.4899797439575195, time 30.55991554260254\n",
      "Evaluate loss 3.4829626083374023, time 30.796093702316284\n",
      "Evaluate loss 3.4148550033569336, time 31.032618045806885\n",
      "Evaluate loss 3.415602207183838, time 31.31377911567688\n",
      "Evaluate loss 3.4941282272338867, time 31.611719131469727\n",
      "Evaluate loss 3.4810259342193604, time 31.88610816001892\n",
      "Evaluate loss 3.537951707839966, time 32.16020393371582\n",
      "Evaluate loss 3.569493293762207, time 32.4881706237793\n",
      "Evaluate loss 3.6406078338623047, time 32.72820258140564\n",
      "Evaluate loss 3.563905715942383, time 32.96172642707825\n",
      "Evaluate loss 3.5971779823303223, time 33.30514168739319\n",
      "Evaluate loss 3.5619757175445557, time 33.541937828063965\n",
      "Evaluate loss 3.443448781967163, time 33.77674698829651\n",
      "Evaluate loss 3.4126832485198975, time 34.13243365287781\n",
      "Evaluate loss 3.335310935974121, time 34.366658449172974\n",
      "Evaluate loss 3.4145636558532715, time 34.74649477005005\n",
      "Evaluate loss 3.274092674255371, time 34.98644948005676\n",
      "Evaluate loss 3.3113677501678467, time 35.37983512878418\n",
      "Evaluate loss 3.3533267974853516, time 35.61549139022827\n",
      "Evaluate loss 3.5072405338287354, time 35.97102880477905\n",
      "Evaluate loss 3.432405471801758, time 36.206931829452515\n",
      "Evaluate loss 3.495042562484741, time 36.441899061203\n",
      "Evaluate loss 3.3226513862609863, time 36.78505563735962\n",
      "Evaluate loss 3.3599300384521484, time 37.01854968070984\n",
      "Evaluate loss 3.35353684425354, time 37.35693144798279\n",
      "Evaluate loss 3.520841121673584, time 37.591248750686646\n",
      "Evaluate loss 3.528569221496582, time 37.826889753341675\n",
      "Evaluate loss 3.609773874282837, time 38.18788433074951\n",
      "Evaluate loss 3.5089364051818848, time 38.42564058303833\n",
      "Evaluate loss 3.6468899250030518, time 38.75637412071228\n",
      "Evaluate loss 3.642940044403076, time 38.993584871292114\n",
      "Evaluate loss 3.698887586593628, time 39.31624150276184\n",
      "Evaluate loss 3.652912139892578, time 39.553168296813965\n",
      "Evaluate loss 3.633967399597168, time 39.786781311035156\n",
      "Evaluate loss 3.56892728805542, time 40.1296648979187\n",
      "Evaluate loss 3.5737435817718506, time 40.370336055755615\n",
      "Evaluate loss 3.498140335083008, time 40.65072798728943\n",
      "Evaluate loss 3.5603063106536865, time 40.947930335998535\n",
      "Evaluate loss 3.5641276836395264, time 41.19043946266174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 3.476344347000122, time 41.54769444465637\n",
      "Evaluate loss 3.428722858428955, time 41.78670310974121\n",
      "Evaluate loss 3.406343460083008, time 42.02679634094238\n",
      "Evaluate loss 3.460768461227417, time 42.36982178688049\n",
      "Evaluate loss 3.542360305786133, time 42.61316251754761\n",
      "Evaluate loss 3.4489026069641113, time 42.93291449546814\n",
      "Evaluate loss 3.468369245529175, time 43.184099197387695\n",
      "Evaluate loss 3.471867322921753, time 43.420939207077026\n",
      "Evaluate loss 3.54521107673645, time 43.69525361061096\n",
      "Evaluate loss 3.460273265838623, time 43.99702858924866\n",
      "Evaluate loss 3.636570453643799, time 44.235997915267944\n",
      "Evaluate loss 3.5865182876586914, time 44.54841065406799\n",
      "Evaluate loss 3.6147022247314453, time 44.79630947113037\n",
      "Evaluate loss 3.603364944458008, time 45.12781620025635\n",
      "Evaluate loss 3.691828727722168, time 45.367536544799805\n",
      "Evaluate loss 3.696754217147827, time 45.71440005302429\n",
      "Evaluate loss 3.730435371398926, time 45.95170497894287\n",
      "Evaluate loss 3.6746490001678467, time 46.187652826309204\n",
      "Evaluate loss 3.628530502319336, time 46.5473895072937\n",
      "Evaluate loss 3.5710558891296387, time 46.7845196723938\n",
      "Evaluate loss 3.556729793548584, time 47.103468894958496\n",
      "Evaluate loss 3.5357494354248047, time 47.340824604034424\n",
      "Evaluate loss 3.5474584102630615, time 47.57703399658203\n",
      "Evaluate loss 3.5863633155822754, time 47.918131828308105\n",
      "Evaluate loss 3.5218913555145264, time 48.165387868881226\n",
      "Evaluate loss 3.5508906841278076, time 48.40319848060608\n",
      "Evaluate loss 3.5713536739349365, time 48.74275469779968\n",
      "Evaluate loss 3.5920779705047607, time 48.97946548461914\n",
      "Evaluate loss 3.63527250289917, time 49.322423219680786\n",
      "Evaluate loss 3.5546581745147705, time 49.557452917099\n",
      "Evaluate loss 3.6689157485961914, time 49.89374256134033\n",
      "Evaluate loss 3.6762866973876953, time 50.13292455673218\n",
      "Evaluate loss 3.645157814025879, time 50.367284536361694\n",
      "Evaluate loss 3.713735580444336, time 50.72600483894348\n",
      "Evaluate loss 3.7367618083953857, time 50.96438789367676\n",
      "Evaluate loss 3.750788450241089, time 51.200278520584106\n",
      "Evaluate loss 3.8139312267303467, time 51.554758071899414\n",
      "Evaluate loss 3.7201337814331055, time 51.791733503341675\n",
      "Evaluate loss 3.6369731426239014, time 52.11255216598511\n",
      "Evaluate loss 3.544058322906494, time 52.35696482658386\n",
      "Evaluate loss 3.5834946632385254, time 52.72014832496643\n",
      "Evaluate loss 3.5646636486053467, time 52.96462368965149\n",
      "Evaluate loss 3.4875848293304443, time 53.32985258102417\n",
      "Evaluate loss 3.441257953643799, time 53.562938928604126\n",
      "Evaluate loss 3.3863818645477295, time 53.90897798538208\n",
      "Evaluate loss 3.5393569469451904, time 54.14730215072632\n"
     ]
    }
   ],
   "source": [
    "evaluate_step(test_word, test_char, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
