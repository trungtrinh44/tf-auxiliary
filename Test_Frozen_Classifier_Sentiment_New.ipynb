{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_v2 import build_lm_classifier_inference, LSTM_SAVED_STATE\n",
    "from utils import get_batch_classifier_inference, clean_text_v3 as clean_text\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we import the graph_def into a new Graph and returns it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph(\"106_sa/checkpoints/class_cpu/frozen.pb-4500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = graph.get_tensor_by_name('prefix/LanguageModel/fw_inputs:0')\n",
    "seq_lens = graph.get_tensor_by_name('prefix/LanguageModel/seq_lens:0')\n",
    "char_lens = graph.get_tensor_by_name('prefix/LanguageModel/fw_char_lens:0')\n",
    "bptt = graph.get_tensor_by_name('prefix/LanguageModel/bptt:0')\n",
    "predict_prob = graph.get_tensor_by_name('prefix/Classifier/Softmax:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config, graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('106_sa/word2idx.json', 'r') as inp:\n",
    "    word2idx = json.load(inp)\n",
    "with open('106_sa/char2idx.json', 'r') as inp:\n",
    "    char2idx = json.load(inp)\n",
    "word2char = {w: [char2idx[c] for c in w] for w in word2idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts, bsz=32):\n",
    "    texts = [clean_text(x.strip()) for x in texts]\n",
    "    texts = np.array([[word2char.get(w, word2char['<UNK>']) for w in sent] for sent in texts])\n",
    "    results = []\n",
    "    for chars, lens, cl in get_batch_classifier_inference(texts, bsz):\n",
    "        probs = session.run(predict_prob, feed_dict={\n",
    "            inputs: chars, seq_lens: lens,\n",
    "            char_lens: cl, bptt: 20\n",
    "        })\n",
    "        results.append(probs)\n",
    "    return np.concatenate(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = {'POS': 2, 'NEU': 1, 'NEG': 0}\n",
    "with open('SentimentAnalysis/test_raw_ANS.txt', 'r') as inp:\n",
    "    lines = inp.readlines()\n",
    "    test_data = lines[::2]\n",
    "    test_label = [label2idx[x.strip()] for x in lines[1::2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6834    0.7400    0.7106       350\n",
      "           1     0.6725    0.6571    0.6647       350\n",
      "           2     0.7872    0.7400    0.7629       350\n",
      "\n",
      "   micro avg     0.7124    0.7124    0.7124      1050\n",
      "   macro avg     0.7144    0.7124    0.7127      1050\n",
      "weighted avg     0.7144    0.7124    0.7127      1050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=test_label, y_pred=np.argmax(preds, axis=1), digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
