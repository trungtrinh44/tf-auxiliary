{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from model_v2 import LanguageModel\n",
    "from tqdm import tqdm_notebook\n",
    "from utils import clean_text\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('102/word2idx.json', 'r') as inp:\n",
    "    word2idx = json.load(inp)\n",
    "with open('102/char2idx.json', 'r') as inp:\n",
    "    char2idx = json.load(inp)\n",
    "idx2word = {k: v for v, k in word2idx.items()}\n",
    "idx2char = {k: v for v, k in char2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "with open('102/checkpoints/model_configs.json', 'r') as inp:\n",
    "    params = json.load(inp)\n",
    "\n",
    "model = LanguageModel(**params, is_training=False, is_encoding=True)\n",
    "\n",
    "model.build_model()\n",
    "saver = tf.train.Saver([x for x in tf.global_variables() if x not in tf.get_collection('LSTM_SAVED_STATE')])\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from 102/checkpoints/test/model.cpkt-1045430\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, '102/checkpoints/test/model.cpkt-1045430')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = tf.concat((model.layerwise_avg[-1], model.layerwise_encode[-1]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sentences):\n",
    "    sen_max_len = max(len(x) for x in sentences)\n",
    "    word_lens = [[len(w) for w in x] for x in sentences]\n",
    "    word_max_len = max(w for x in word_lens for w in x)\n",
    "    arr = np.zeros(shape=(len(sentences), sen_max_len, word_max_len))\n",
    "    lens = np.zeros(shape=(len(sentences), sen_max_len))\n",
    "    for ir in range(len(sentences)):\n",
    "        sentence = sentences[ir]\n",
    "        lens[ir][:len(word_lens[ir])] = word_lens[ir]\n",
    "        for ic in range(len(sentence)):\n",
    "            word = sentence[ic]\n",
    "            arr[ir][ic][:len(word)] = word\n",
    "    return np.transpose(arr, (1, 0, 2)), np.transpose(lens, (1, 0))\n",
    "\n",
    "def __embed_sequence(sentences):\n",
    "    unk_char = [char2idx[x] for x in '<UNK>']\n",
    "    sentences = [[[char2idx[x] for x in word] if word in word2idx else unk_char for word in sentence] for sentence in sentences]\n",
    "    seq_len = [len(x) for x in sentences]\n",
    "    inputs, char_lens = pad_sequence(sentences)\n",
    "    emb = sess.run(model.layerwise_avg[-1], feed_dict={\n",
    "        model.inputs: inputs, model.seq_lens: seq_len, model.bptt: 1, model.char_lens: char_lens\n",
    "    })\n",
    "    return emb\n",
    "def embed_sentence(sentences):\n",
    "#     sentence = re.sub(r'(http[s]?://)?(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', sentence)\n",
    "#     sentence = re.sub(r\"#[^\\s]*\", ' ', sentence)\n",
    "    sentences = [clean_text(x, add_bos=True, add_eos=True).split() for x in sentences]\n",
    "    return __embed_sequence(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('baomoi_noseg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/envs/tfp/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "titles, _, cate, _ = train_test_split(data['title'], data['cate'], train_size=10000, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(texts, bs):\n",
    "    for i in range(0, len(texts), bs):\n",
    "        yield texts[i:i+bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf84efce603243a3a25685ee2d2b9514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding = [embed_sentence(x) for x in tqdm_notebook(get_batch(titles, 32))]    \n",
    "# data['embedding'] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.concatenate(embedding, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split([x for x in zip(embedding, titles)], cate, train_size=1500, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.stack([x for x, _ in X_train], axis=0)\n",
    "test_data = np.stack([x for x, _ in X_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(n_jobs=4, solver='lbfgs', multi_class='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto', n_jobs=4,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                       Giáo dục       1.00      1.00      1.00        48\n",
      "     Giáo dục/Học bổng - Du học       1.00      1.00      1.00        50\n",
      "      Giáo dục/Đào tạo - Thi cử       1.00      1.00      1.00        50\n",
      "            Giải trí/Thời trang       1.00      1.00      1.00        41\n",
      "               Giải trí/Âm nhạc       1.00      1.00      1.00        46\n",
      "Giải trí/Điện ảnh - Truyền hình       1.00      1.00      1.00        36\n",
      "      KH - CN/CNTT - Viễn thông       1.00      1.00      1.00        52\n",
      "    KH - CN/Khoa học - Tự nhiên       1.00      1.00      1.00        64\n",
      "   KH - CN/Thiết bị - Phần cứng       1.00      1.00      1.00        55\n",
      "            Kinh tế/Chứng khoán       1.00      1.00      1.00        53\n",
      "             Kinh tế/Kinh doanh       1.00      1.00      1.00        50\n",
      "    Kinh tế/Lao động - Việc làm       1.00      1.00      1.00        66\n",
      "              Kinh tế/Tài chính       1.00      1.00      1.00        44\n",
      " Nhà đất/Không gian - Kiến trúc       1.00      1.00      1.00        41\n",
      "    Nhà đất/Quản lý - Quy hoạch       1.00      1.00      1.00        50\n",
      "    Pháp luật/An ninh - Trật tự       1.00      1.00      1.00        52\n",
      "     Pháp luật/Hình sự - Dân sự       1.00      1.00      1.00        47\n",
      "                       Thế giới       1.00      1.00      1.00        56\n",
      "               Thể thao/Bóng đá       1.00      1.00      1.00        43\n",
      "              Thể thao/Quần vợt       1.00      1.00      1.00        41\n",
      "                Văn hóa/Du lịch       1.00      1.00      1.00        59\n",
      "             Văn hóa/Nghệ thuật       1.00      1.00      1.00        45\n",
      "                Văn hóa/Ẩm thực       1.00      1.00      1.00        56\n",
      "                          Xe cộ       1.00      1.00      1.00        56\n",
      "              Xã hội/Giao thông       1.00      1.00      1.00        39\n",
      "    Xã hội/Môi trường - Khí hậu       1.00      1.00      1.00        47\n",
      "                 Xã hội/Thời sự       1.00      1.00      1.00        39\n",
      "  Đời sống/Dinh dưỡng - Làm đẹp       1.00      1.00      1.00        55\n",
      "       Đời sống/Sức khỏe - Y tế       1.00      1.00      1.00        60\n",
      "   Đời sống/Tình yêu - Hôn nhân       1.00      1.00      1.00        59\n",
      "\n",
      "                      micro avg       1.00      1.00      1.00      1500\n",
      "                      macro avg       1.00      1.00      1.00      1500\n",
      "                   weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                       Giáo dục       0.56      0.50      0.53       246\n",
      "     Giáo dục/Học bổng - Du học       0.59      0.63      0.61       273\n",
      "      Giáo dục/Đào tạo - Thi cử       0.89      0.89      0.89       265\n",
      "            Giải trí/Thời trang       0.72      0.66      0.69       298\n",
      "               Giải trí/Âm nhạc       0.64      0.70      0.67       290\n",
      "Giải trí/Điện ảnh - Truyền hình       0.64      0.57      0.60       267\n",
      "      KH - CN/CNTT - Viễn thông       0.60      0.60      0.60       296\n",
      "    KH - CN/Khoa học - Tự nhiên       0.52      0.66      0.59       307\n",
      "   KH - CN/Thiết bị - Phần cứng       0.82      0.77      0.79       280\n",
      "            Kinh tế/Chứng khoán       0.71      0.79      0.75       290\n",
      "             Kinh tế/Kinh doanh       0.42      0.41      0.41       283\n",
      "    Kinh tế/Lao động - Việc làm       0.47      0.58      0.52       304\n",
      "              Kinh tế/Tài chính       0.69      0.54      0.60       278\n",
      " Nhà đất/Không gian - Kiến trúc       0.80      0.65      0.72       293\n",
      "    Nhà đất/Quản lý - Quy hoạch       0.58      0.59      0.59       286\n",
      "    Pháp luật/An ninh - Trật tự       0.45      0.37      0.41       265\n",
      "     Pháp luật/Hình sự - Dân sự       0.72      0.60      0.66       286\n",
      "                       Thế giới       0.77      0.78      0.78       315\n",
      "               Thể thao/Bóng đá       0.89      0.88      0.88       276\n",
      "              Thể thao/Quần vợt       0.95      0.90      0.92       258\n",
      "                Văn hóa/Du lịch       0.44      0.60      0.51       281\n",
      "             Văn hóa/Nghệ thuật       0.61      0.56      0.58       275\n",
      "                Văn hóa/Ẩm thực       0.67      0.75      0.71       253\n",
      "                          Xe cộ       0.88      0.87      0.87       294\n",
      "              Xã hội/Giao thông       0.72      0.60      0.65       283\n",
      "    Xã hội/Môi trường - Khí hậu       0.73      0.69      0.71       292\n",
      "                 Xã hội/Thời sự       0.61      0.56      0.58       275\n",
      "  Đời sống/Dinh dưỡng - Làm đẹp       0.73      0.73      0.73       299\n",
      "       Đời sống/Sức khỏe - Y tế       0.66      0.65      0.65       312\n",
      "   Đời sống/Tình yêu - Hôn nhân       0.55      0.70      0.62       280\n",
      "\n",
      "                      micro avg       0.66      0.66      0.66      8500\n",
      "                      macro avg       0.67      0.66      0.66      8500\n",
      "                   weighted avg       0.67      0.66      0.66      8500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_train, y_pred=classifier.predict(train_data)))\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=classifier.predict(test_data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
